I0814 21:51:16.924517  2973 caffe.cpp:185] Using GPUs 0
I0814 21:51:16.924903  2973 caffe.cpp:190] GPU 0: Tesla K80
I0814 21:51:17.206135  2973 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.001
display: 1000
max_iter: 20000
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.004
stepsize: 10000
snapshot: 10000
snapshot_prefix: "ts_cifar10/"
solver_mode: GPU
device_id: 0
net: "Teacher-Student-Training/cifar10/ts_cifar10.prototxt"
I0814 21:51:17.206290  2973 solver.cpp:91] Creating training net from net file: Teacher-Student-Training/cifar10/ts_cifar10.prototxt
I0814 21:51:17.207141  2973 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0814 21:51:17.207180  2973 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0814 21:51:17.207383  2973 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "/home/ubuntu/caffe/examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/ubuntu/caffe/examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv_s_1"
  type: "Convolution"
  bottom: "data"
  top: "conv_s_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool_s_1"
  type: "Pooling"
  bottom: "conv_s_1"
  top: "pool_s_1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu_s_1"
  type: "ReLU"
  bottom: "pool_s_1"
  top: "pool_s_1"
}
layer {
  name: "norm_s_1"
  type: "LRN"
  bottom: "pool_s_1"
  top: "norm_s_1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv_s_2"
  type: "Convolution"
  bottom: "norm_s_1"
  top: "conv_s_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_s_2"
  type: "ReLU"
  bottom: "conv_s_2"
  top: "conv_s_2"
}
layer {
  name: "pool_s_2"
  type: "Pooling"
  bottom: "conv_s_2"
  top: "pool_s_2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm_s_2"
  type: "LRN"
  bottom: "pool_s_2"
  top: "norm_s_2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv_s_3"
  type: "Convolution"
  bottom: "norm_s_2"
  top: "conv_s_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_s_3"
  type: "ReLU"
  bottom: "conv_s_3"
  top: "conv_s_3"
}
layer {
  name: "pool_s_3"
  type: "Pooling"
  bottom: "conv_s_3"
  top: "pool_s_3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip_s_1"
  type: "InnerProduct"
  bottom: "pool_s_3"
  top: "ip_s_1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv_t_1"
  type: "Convolution"
  bottom: "data"
  top: "conv_t_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool_t_1"
  type: "Pooling"
  bottom: "conv_t_1"
  top: "pool_t_1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu_t_1"
  type: "ReLU"
  bottom: "pool_t_1"
  top: "pool_t_1"
}
layer {
  name: "norm_t_1"
  type: "LRN"
  bottom: "pool_t_1"
  top: "norm_t_1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv_t_2"
  type: "Convolution"
  bottom: "norm_t_1"
  top: "conv_t_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_t_2"
  type: "ReLU"
  bottom: "conv_t_2"
  top: "conv_t_2"
}
layer {
  name: "pool_t_2"
  type: "Pooling"
  bottom: "conv_t_2"
  top: "pool_t_2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm_t_2"
  type: "LRN"
  bottom: "pool_t_2"
  top: "norm_t_2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv_t_3"
  type: "Convolution"
  bottom: "norm_t_2"
  top: "conv_t_3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_t_3"
  type: "ReLU"
  bottom: "conv_t_3"
  top: "conv_t_3"
}
layer {
  name: "pool_t_3"
  type: "Pooling"
  bottom: "conv_t_3"
  top: "pool_t_3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip_t_1"
  type: "InnerProduct"
  bottom: "pool_t_3"
  top: "ip_t_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "sm_s_1"
  type: "Softmax"
  bottom: "ip_s_1"
  top: "sm_s_1"
}
layer {
  name: "sm_t_1"
  type: "Softmax"
  bottom: "ip_t_1"
  top: "sm_t_1"
}
layer {
  name: "ts_loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "sm_s_1"
  bottom: "sm_t_1"
  top: "ts_loss"
  loss_weight: 0.05
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip_s_1"
  bottom: "label"
  top: "loss"
  loss_weight: 0.95
}
I0814 21:51:17.207597  2973 layer_factory.hpp:77] Creating layer cifar
I0814 21:51:17.208737  2973 net.cpp:91] Creating Layer cifar
I0814 21:51:17.208768  2973 net.cpp:399] cifar -> data
I0814 21:51:17.208819  2973 net.cpp:399] cifar -> label
I0814 21:51:17.208851  2973 data_transformer.cpp:25] Loading mean file from: /home/ubuntu/caffe/examples/cifar10/mean.binaryproto
I0814 21:51:17.209561  2976 db_lmdb.cpp:35] Opened lmdb /home/ubuntu/caffe/examples/cifar10/cifar10_train_lmdb
I0814 21:51:17.221343  2973 data_layer.cpp:41] output data size: 100,3,32,32
I0814 21:51:17.225584  2973 net.cpp:141] Setting up cifar
I0814 21:51:17.225610  2973 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0814 21:51:17.225620  2973 net.cpp:148] Top shape: 100 (100)
I0814 21:51:17.225625  2973 net.cpp:156] Memory required for data: 1229200
I0814 21:51:17.225639  2973 layer_factory.hpp:77] Creating layer data_cifar_0_split
I0814 21:51:17.225664  2973 net.cpp:91] Creating Layer data_cifar_0_split
I0814 21:51:17.225677  2973 net.cpp:425] data_cifar_0_split <- data
I0814 21:51:17.225705  2973 net.cpp:399] data_cifar_0_split -> data_cifar_0_split_0
I0814 21:51:17.225724  2973 net.cpp:399] data_cifar_0_split -> data_cifar_0_split_1
I0814 21:51:17.225785  2973 net.cpp:141] Setting up data_cifar_0_split
I0814 21:51:17.225801  2973 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0814 21:51:17.225810  2973 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0814 21:51:17.225816  2973 net.cpp:156] Memory required for data: 3686800
I0814 21:51:17.225822  2973 layer_factory.hpp:77] Creating layer conv_s_1
I0814 21:51:17.225857  2973 net.cpp:91] Creating Layer conv_s_1
I0814 21:51:17.225888  2973 net.cpp:425] conv_s_1 <- data_cifar_0_split_0
I0814 21:51:17.225905  2973 net.cpp:399] conv_s_1 -> conv_s_1
I0814 21:51:17.397233  2973 net.cpp:141] Setting up conv_s_1
I0814 21:51:17.397277  2973 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I0814 21:51:17.397285  2973 net.cpp:156] Memory required for data: 16794000
I0814 21:51:17.397317  2973 layer_factory.hpp:77] Creating layer pool_s_1
I0814 21:51:17.397343  2973 net.cpp:91] Creating Layer pool_s_1
I0814 21:51:17.397351  2973 net.cpp:425] pool_s_1 <- conv_s_1
I0814 21:51:17.397366  2973 net.cpp:399] pool_s_1 -> pool_s_1
I0814 21:51:17.397442  2973 net.cpp:141] Setting up pool_s_1
I0814 21:51:17.397459  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.397465  2973 net.cpp:156] Memory required for data: 20070800
I0814 21:51:17.397471  2973 layer_factory.hpp:77] Creating layer relu_s_1
I0814 21:51:17.397486  2973 net.cpp:91] Creating Layer relu_s_1
I0814 21:51:17.397514  2973 net.cpp:425] relu_s_1 <- pool_s_1
I0814 21:51:17.397524  2973 net.cpp:386] relu_s_1 -> pool_s_1 (in-place)
I0814 21:51:17.397744  2973 net.cpp:141] Setting up relu_s_1
I0814 21:51:17.397764  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.397770  2973 net.cpp:156] Memory required for data: 23347600
I0814 21:51:17.397778  2973 layer_factory.hpp:77] Creating layer norm_s_1
I0814 21:51:17.397799  2973 net.cpp:91] Creating Layer norm_s_1
I0814 21:51:17.397807  2973 net.cpp:425] norm_s_1 <- pool_s_1
I0814 21:51:17.397816  2973 net.cpp:399] norm_s_1 -> norm_s_1
I0814 21:51:17.398438  2973 net.cpp:141] Setting up norm_s_1
I0814 21:51:17.398463  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.398469  2973 net.cpp:156] Memory required for data: 26624400
I0814 21:51:17.398475  2973 layer_factory.hpp:77] Creating layer conv_s_2
I0814 21:51:17.398499  2973 net.cpp:91] Creating Layer conv_s_2
I0814 21:51:17.398506  2973 net.cpp:425] conv_s_2 <- norm_s_1
I0814 21:51:17.398521  2973 net.cpp:399] conv_s_2 -> conv_s_2
I0814 21:51:17.401034  2973 net.cpp:141] Setting up conv_s_2
I0814 21:51:17.401060  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.401067  2973 net.cpp:156] Memory required for data: 29901200
I0814 21:51:17.401083  2973 layer_factory.hpp:77] Creating layer relu_s_2
I0814 21:51:17.401095  2973 net.cpp:91] Creating Layer relu_s_2
I0814 21:51:17.401101  2973 net.cpp:425] relu_s_2 <- conv_s_2
I0814 21:51:17.401116  2973 net.cpp:386] relu_s_2 -> conv_s_2 (in-place)
I0814 21:51:17.401311  2973 net.cpp:141] Setting up relu_s_2
I0814 21:51:17.401332  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.401340  2973 net.cpp:156] Memory required for data: 33178000
I0814 21:51:17.401345  2973 layer_factory.hpp:77] Creating layer pool_s_2
I0814 21:51:17.401358  2973 net.cpp:91] Creating Layer pool_s_2
I0814 21:51:17.401365  2973 net.cpp:425] pool_s_2 <- conv_s_2
I0814 21:51:17.401376  2973 net.cpp:399] pool_s_2 -> pool_s_2
I0814 21:51:17.401697  2973 net.cpp:141] Setting up pool_s_2
I0814 21:51:17.401720  2973 net.cpp:148] Top shape: 100 32 8 8 (204800)
I0814 21:51:17.401726  2973 net.cpp:156] Memory required for data: 33997200
I0814 21:51:17.401733  2973 layer_factory.hpp:77] Creating layer norm_s_2
I0814 21:51:17.401747  2973 net.cpp:91] Creating Layer norm_s_2
I0814 21:51:17.401756  2973 net.cpp:425] norm_s_2 <- pool_s_2
I0814 21:51:17.401764  2973 net.cpp:399] norm_s_2 -> norm_s_2
I0814 21:51:17.402252  2973 net.cpp:141] Setting up norm_s_2
I0814 21:51:17.402274  2973 net.cpp:148] Top shape: 100 32 8 8 (204800)
I0814 21:51:17.402281  2973 net.cpp:156] Memory required for data: 34816400
I0814 21:51:17.402288  2973 layer_factory.hpp:77] Creating layer conv_s_3
I0814 21:51:17.402308  2973 net.cpp:91] Creating Layer conv_s_3
I0814 21:51:17.402315  2973 net.cpp:425] conv_s_3 <- norm_s_2
I0814 21:51:17.402331  2973 net.cpp:399] conv_s_3 -> conv_s_3
I0814 21:51:17.404723  2973 net.cpp:141] Setting up conv_s_3
I0814 21:51:17.404748  2973 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0814 21:51:17.404783  2973 net.cpp:156] Memory required for data: 36454800
I0814 21:51:17.404801  2973 layer_factory.hpp:77] Creating layer relu_s_3
I0814 21:51:17.404814  2973 net.cpp:91] Creating Layer relu_s_3
I0814 21:51:17.404820  2973 net.cpp:425] relu_s_3 <- conv_s_3
I0814 21:51:17.404830  2973 net.cpp:386] relu_s_3 -> conv_s_3 (in-place)
I0814 21:51:17.405133  2973 net.cpp:141] Setting up relu_s_3
I0814 21:51:17.405154  2973 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0814 21:51:17.405161  2973 net.cpp:156] Memory required for data: 38093200
I0814 21:51:17.405169  2973 layer_factory.hpp:77] Creating layer pool_s_3
I0814 21:51:17.405179  2973 net.cpp:91] Creating Layer pool_s_3
I0814 21:51:17.405185  2973 net.cpp:425] pool_s_3 <- conv_s_3
I0814 21:51:17.405199  2973 net.cpp:399] pool_s_3 -> pool_s_3
I0814 21:51:17.405411  2973 net.cpp:141] Setting up pool_s_3
I0814 21:51:17.405431  2973 net.cpp:148] Top shape: 100 64 4 4 (102400)
I0814 21:51:17.405436  2973 net.cpp:156] Memory required for data: 38502800
I0814 21:51:17.405442  2973 layer_factory.hpp:77] Creating layer ip_s_1
I0814 21:51:17.405458  2973 net.cpp:91] Creating Layer ip_s_1
I0814 21:51:17.405465  2973 net.cpp:425] ip_s_1 <- pool_s_3
I0814 21:51:17.405480  2973 net.cpp:399] ip_s_1 -> ip_s_1
I0814 21:51:17.406613  2973 net.cpp:141] Setting up ip_s_1
I0814 21:51:17.406635  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.406641  2973 net.cpp:156] Memory required for data: 38506800
I0814 21:51:17.406652  2973 layer_factory.hpp:77] Creating layer ip_s_1_ip_s_1_0_split
I0814 21:51:17.406666  2973 net.cpp:91] Creating Layer ip_s_1_ip_s_1_0_split
I0814 21:51:17.406673  2973 net.cpp:425] ip_s_1_ip_s_1_0_split <- ip_s_1
I0814 21:51:17.406682  2973 net.cpp:399] ip_s_1_ip_s_1_0_split -> ip_s_1_ip_s_1_0_split_0
I0814 21:51:17.406694  2973 net.cpp:399] ip_s_1_ip_s_1_0_split -> ip_s_1_ip_s_1_0_split_1
I0814 21:51:17.406761  2973 net.cpp:141] Setting up ip_s_1_ip_s_1_0_split
I0814 21:51:17.406776  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.406785  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.406790  2973 net.cpp:156] Memory required for data: 38514800
I0814 21:51:17.406795  2973 layer_factory.hpp:77] Creating layer conv_t_1
I0814 21:51:17.406814  2973 net.cpp:91] Creating Layer conv_t_1
I0814 21:51:17.406821  2973 net.cpp:425] conv_t_1 <- data_cifar_0_split_1
I0814 21:51:17.406836  2973 net.cpp:399] conv_t_1 -> conv_t_1
I0814 21:51:17.407863  2973 net.cpp:141] Setting up conv_t_1
I0814 21:51:17.407887  2973 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I0814 21:51:17.407894  2973 net.cpp:156] Memory required for data: 51622000
I0814 21:51:17.407910  2973 layer_factory.hpp:77] Creating layer pool_t_1
I0814 21:51:17.407928  2973 net.cpp:91] Creating Layer pool_t_1
I0814 21:51:17.407935  2973 net.cpp:425] pool_t_1 <- conv_t_1
I0814 21:51:17.407946  2973 net.cpp:399] pool_t_1 -> pool_t_1
I0814 21:51:17.408012  2973 net.cpp:141] Setting up pool_t_1
I0814 21:51:17.408030  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.408035  2973 net.cpp:156] Memory required for data: 54898800
I0814 21:51:17.408041  2973 layer_factory.hpp:77] Creating layer relu_t_1
I0814 21:51:17.408051  2973 net.cpp:91] Creating Layer relu_t_1
I0814 21:51:17.408057  2973 net.cpp:425] relu_t_1 <- pool_t_1
I0814 21:51:17.408069  2973 net.cpp:386] relu_t_1 -> pool_t_1 (in-place)
I0814 21:51:17.408362  2973 net.cpp:141] Setting up relu_t_1
I0814 21:51:17.408383  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.408390  2973 net.cpp:156] Memory required for data: 58175600
I0814 21:51:17.408396  2973 layer_factory.hpp:77] Creating layer norm_t_1
I0814 21:51:17.408411  2973 net.cpp:91] Creating Layer norm_t_1
I0814 21:51:17.408418  2973 net.cpp:425] norm_t_1 <- pool_t_1
I0814 21:51:17.408447  2973 net.cpp:399] norm_t_1 -> norm_t_1
I0814 21:51:17.408958  2973 net.cpp:141] Setting up norm_t_1
I0814 21:51:17.408980  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.408987  2973 net.cpp:156] Memory required for data: 61452400
I0814 21:51:17.409011  2973 layer_factory.hpp:77] Creating layer conv_t_2
I0814 21:51:17.409037  2973 net.cpp:91] Creating Layer conv_t_2
I0814 21:51:17.409049  2973 net.cpp:425] conv_t_2 <- norm_t_1
I0814 21:51:17.409061  2973 net.cpp:399] conv_t_2 -> conv_t_2
I0814 21:51:17.410780  2973 net.cpp:141] Setting up conv_t_2
I0814 21:51:17.410805  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.410812  2973 net.cpp:156] Memory required for data: 64729200
I0814 21:51:17.410823  2973 layer_factory.hpp:77] Creating layer relu_t_2
I0814 21:51:17.410838  2973 net.cpp:91] Creating Layer relu_t_2
I0814 21:51:17.410845  2973 net.cpp:425] relu_t_2 <- conv_t_2
I0814 21:51:17.410856  2973 net.cpp:386] relu_t_2 -> conv_t_2 (in-place)
I0814 21:51:17.411058  2973 net.cpp:141] Setting up relu_t_2
I0814 21:51:17.411077  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.411082  2973 net.cpp:156] Memory required for data: 68006000
I0814 21:51:17.411088  2973 layer_factory.hpp:77] Creating layer pool_t_2
I0814 21:51:17.411099  2973 net.cpp:91] Creating Layer pool_t_2
I0814 21:51:17.411106  2973 net.cpp:425] pool_t_2 <- conv_t_2
I0814 21:51:17.411118  2973 net.cpp:399] pool_t_2 -> pool_t_2
I0814 21:51:17.411419  2973 net.cpp:141] Setting up pool_t_2
I0814 21:51:17.411440  2973 net.cpp:148] Top shape: 100 32 8 8 (204800)
I0814 21:51:17.411448  2973 net.cpp:156] Memory required for data: 68825200
I0814 21:51:17.411453  2973 layer_factory.hpp:77] Creating layer norm_t_2
I0814 21:51:17.411468  2973 net.cpp:91] Creating Layer norm_t_2
I0814 21:51:17.411474  2973 net.cpp:425] norm_t_2 <- pool_t_2
I0814 21:51:17.411484  2973 net.cpp:399] norm_t_2 -> norm_t_2
I0814 21:51:17.412063  2973 net.cpp:141] Setting up norm_t_2
I0814 21:51:17.412086  2973 net.cpp:148] Top shape: 100 32 8 8 (204800)
I0814 21:51:17.412093  2973 net.cpp:156] Memory required for data: 69644400
I0814 21:51:17.412099  2973 layer_factory.hpp:77] Creating layer conv_t_3
I0814 21:51:17.412122  2973 net.cpp:91] Creating Layer conv_t_3
I0814 21:51:17.412130  2973 net.cpp:425] conv_t_3 <- norm_t_2
I0814 21:51:17.412143  2973 net.cpp:399] conv_t_3 -> conv_t_3
I0814 21:51:17.414602  2973 net.cpp:141] Setting up conv_t_3
I0814 21:51:17.414628  2973 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0814 21:51:17.414634  2973 net.cpp:156] Memory required for data: 71282800
I0814 21:51:17.414645  2973 layer_factory.hpp:77] Creating layer relu_t_3
I0814 21:51:17.414657  2973 net.cpp:91] Creating Layer relu_t_3
I0814 21:51:17.414664  2973 net.cpp:425] relu_t_3 <- conv_t_3
I0814 21:51:17.414677  2973 net.cpp:386] relu_t_3 -> conv_t_3 (in-place)
I0814 21:51:17.414978  2973 net.cpp:141] Setting up relu_t_3
I0814 21:51:17.414999  2973 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0814 21:51:17.415006  2973 net.cpp:156] Memory required for data: 72921200
I0814 21:51:17.415012  2973 layer_factory.hpp:77] Creating layer pool_t_3
I0814 21:51:17.415030  2973 net.cpp:91] Creating Layer pool_t_3
I0814 21:51:17.415037  2973 net.cpp:425] pool_t_3 <- conv_t_3
I0814 21:51:17.415047  2973 net.cpp:399] pool_t_3 -> pool_t_3
I0814 21:51:17.415271  2973 net.cpp:141] Setting up pool_t_3
I0814 21:51:17.415288  2973 net.cpp:148] Top shape: 100 64 4 4 (102400)
I0814 21:51:17.415294  2973 net.cpp:156] Memory required for data: 73330800
I0814 21:51:17.415300  2973 layer_factory.hpp:77] Creating layer ip_t_1
I0814 21:51:17.415315  2973 net.cpp:91] Creating Layer ip_t_1
I0814 21:51:17.415323  2973 net.cpp:425] ip_t_1 <- pool_t_3
I0814 21:51:17.415333  2973 net.cpp:399] ip_t_1 -> ip_t_1
I0814 21:51:17.415745  2973 net.cpp:141] Setting up ip_t_1
I0814 21:51:17.415760  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.415767  2973 net.cpp:156] Memory required for data: 73334800
I0814 21:51:17.415777  2973 layer_factory.hpp:77] Creating layer sm_s_1
I0814 21:51:17.415788  2973 net.cpp:91] Creating Layer sm_s_1
I0814 21:51:17.415796  2973 net.cpp:425] sm_s_1 <- ip_s_1_ip_s_1_0_split_0
I0814 21:51:17.415805  2973 net.cpp:399] sm_s_1 -> sm_s_1
I0814 21:51:17.416190  2973 net.cpp:141] Setting up sm_s_1
I0814 21:51:17.416227  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.416235  2973 net.cpp:156] Memory required for data: 73338800
I0814 21:51:17.416241  2973 layer_factory.hpp:77] Creating layer sm_t_1
I0814 21:51:17.416251  2973 net.cpp:91] Creating Layer sm_t_1
I0814 21:51:17.416259  2973 net.cpp:425] sm_t_1 <- ip_t_1
I0814 21:51:17.416268  2973 net.cpp:399] sm_t_1 -> sm_t_1
I0814 21:51:17.416550  2973 net.cpp:141] Setting up sm_t_1
I0814 21:51:17.416569  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.416575  2973 net.cpp:156] Memory required for data: 73342800
I0814 21:51:17.416581  2973 layer_factory.hpp:77] Creating layer ts_loss
I0814 21:51:17.416605  2973 net.cpp:91] Creating Layer ts_loss
I0814 21:51:17.416612  2973 net.cpp:425] ts_loss <- sm_s_1
I0814 21:51:17.416620  2973 net.cpp:425] ts_loss <- sm_t_1
I0814 21:51:17.416630  2973 net.cpp:399] ts_loss -> ts_loss
I0814 21:51:17.416712  2973 net.cpp:141] Setting up ts_loss
I0814 21:51:17.416728  2973 net.cpp:148] Top shape: (1)
I0814 21:51:17.416733  2973 net.cpp:151]     with loss weight 0.05
I0814 21:51:17.416777  2973 net.cpp:156] Memory required for data: 73342804
I0814 21:51:17.416785  2973 layer_factory.hpp:77] Creating layer loss
I0814 21:51:17.416800  2973 net.cpp:91] Creating Layer loss
I0814 21:51:17.416808  2973 net.cpp:425] loss <- ip_s_1_ip_s_1_0_split_1
I0814 21:51:17.416816  2973 net.cpp:425] loss <- label
I0814 21:51:17.416826  2973 net.cpp:399] loss -> loss
I0814 21:51:17.416842  2973 layer_factory.hpp:77] Creating layer loss
I0814 21:51:17.417237  2973 net.cpp:141] Setting up loss
I0814 21:51:17.417258  2973 net.cpp:148] Top shape: (1)
I0814 21:51:17.417264  2973 net.cpp:151]     with loss weight 0.95
I0814 21:51:17.417276  2973 net.cpp:156] Memory required for data: 73342808
I0814 21:51:17.417282  2973 net.cpp:217] loss needs backward computation.
I0814 21:51:17.417290  2973 net.cpp:217] ts_loss needs backward computation.
I0814 21:51:17.417296  2973 net.cpp:219] sm_t_1 does not need backward computation.
I0814 21:51:17.417307  2973 net.cpp:217] sm_s_1 needs backward computation.
I0814 21:51:17.417315  2973 net.cpp:219] ip_t_1 does not need backward computation.
I0814 21:51:17.417320  2973 net.cpp:219] pool_t_3 does not need backward computation.
I0814 21:51:17.417327  2973 net.cpp:219] relu_t_3 does not need backward computation.
I0814 21:51:17.417333  2973 net.cpp:219] conv_t_3 does not need backward computation.
I0814 21:51:17.417340  2973 net.cpp:219] norm_t_2 does not need backward computation.
I0814 21:51:17.417346  2973 net.cpp:219] pool_t_2 does not need backward computation.
I0814 21:51:17.417351  2973 net.cpp:219] relu_t_2 does not need backward computation.
I0814 21:51:17.417357  2973 net.cpp:219] conv_t_2 does not need backward computation.
I0814 21:51:17.417363  2973 net.cpp:219] norm_t_1 does not need backward computation.
I0814 21:51:17.417369  2973 net.cpp:219] relu_t_1 does not need backward computation.
I0814 21:51:17.417376  2973 net.cpp:219] pool_t_1 does not need backward computation.
I0814 21:51:17.417382  2973 net.cpp:219] conv_t_1 does not need backward computation.
I0814 21:51:17.417387  2973 net.cpp:217] ip_s_1_ip_s_1_0_split needs backward computation.
I0814 21:51:17.417394  2973 net.cpp:217] ip_s_1 needs backward computation.
I0814 21:51:17.417400  2973 net.cpp:217] pool_s_3 needs backward computation.
I0814 21:51:17.417407  2973 net.cpp:217] relu_s_3 needs backward computation.
I0814 21:51:17.417412  2973 net.cpp:217] conv_s_3 needs backward computation.
I0814 21:51:17.417418  2973 net.cpp:217] norm_s_2 needs backward computation.
I0814 21:51:17.417423  2973 net.cpp:217] pool_s_2 needs backward computation.
I0814 21:51:17.417429  2973 net.cpp:217] relu_s_2 needs backward computation.
I0814 21:51:17.417435  2973 net.cpp:217] conv_s_2 needs backward computation.
I0814 21:51:17.417441  2973 net.cpp:217] norm_s_1 needs backward computation.
I0814 21:51:17.417448  2973 net.cpp:217] relu_s_1 needs backward computation.
I0814 21:51:17.417453  2973 net.cpp:217] pool_s_1 needs backward computation.
I0814 21:51:17.417472  2973 net.cpp:217] conv_s_1 needs backward computation.
I0814 21:51:17.417479  2973 net.cpp:219] data_cifar_0_split does not need backward computation.
I0814 21:51:17.417486  2973 net.cpp:219] cifar does not need backward computation.
I0814 21:51:17.417492  2973 net.cpp:261] This network produces output loss
I0814 21:51:17.417498  2973 net.cpp:261] This network produces output ts_loss
I0814 21:51:17.417536  2973 net.cpp:274] Network initialization done.
I0814 21:51:17.418393  2973 solver.cpp:181] Creating test net (#0) specified by net file: Teacher-Student-Training/cifar10/ts_cifar10.prototxt
I0814 21:51:17.418483  2973 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0814 21:51:17.418776  2973 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/ubuntu/caffe/examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/ubuntu/caffe/examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv_s_1"
  type: "Convolution"
  bottom: "data"
  top: "conv_s_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool_s_1"
  type: "Pooling"
  bottom: "conv_s_1"
  top: "pool_s_1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu_s_1"
  type: "ReLU"
  bottom: "pool_s_1"
  top: "pool_s_1"
}
layer {
  name: "norm_s_1"
  type: "LRN"
  bottom: "pool_s_1"
  top: "norm_s_1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv_s_2"
  type: "Convolution"
  bottom: "norm_s_1"
  top: "conv_s_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_s_2"
  type: "ReLU"
  bottom: "conv_s_2"
  top: "conv_s_2"
}
layer {
  name: "pool_s_2"
  type: "Pooling"
  bottom: "conv_s_2"
  top: "pool_s_2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm_s_2"
  type: "LRN"
  bottom: "pool_s_2"
  top: "norm_s_2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv_s_3"
  type: "Convolution"
  bottom: "norm_s_2"
  top: "conv_s_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_s_3"
  type: "ReLU"
  bottom: "conv_s_3"
  top: "conv_s_3"
}
layer {
  name: "pool_s_3"
  type: "Pooling"
  bottom: "conv_s_3"
  top: "pool_s_3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip_s_1"
  type: "InnerProduct"
  bottom: "pool_s_3"
  top: "ip_s_1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv_t_1"
  type: "Convolution"
  bottom: "data"
  top: "conv_t_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool_t_1"
  type: "Pooling"
  bottom: "conv_t_1"
  top: "pool_t_1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu_t_1"
  type: "ReLU"
  bottom: "pool_t_1"
  top: "pool_t_1"
}
layer {
  name: "norm_t_1"
  type: "LRN"
  bottom: "pool_t_1"
  top: "norm_t_1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv_t_2"
  type: "Convolution"
  bottom: "norm_t_1"
  top: "conv_t_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_t_2"
  type: "ReLU"
  bottom: "conv_t_2"
  top: "conv_t_2"
}
layer {
  name: "pool_t_2"
  type: "Pooling"
  bottom: "conv_t_2"
  top: "pool_t_2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm_t_2"
  type: "LRN"
  bottom: "pool_t_2"
  top: "norm_t_2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv_t_3"
  type: "Convolution"
  bottom: "norm_t_2"
  top: "conv_t_3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_t_3"
  type: "ReLU"
  bottom: "conv_t_3"
  top: "conv_t_3"
}
layer {
  name: "pool_t_3"
  type: "Pooling"
  bottom: "conv_t_3"
  top: "pool_t_3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip_t_1"
  type: "InnerProduct"
  bottom: "pool_t_3"
  top: "ip_t_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "sm_s_1"
  type: "Softmax"
  bottom: "ip_s_1"
  top: "sm_s_1"
}
layer {
  name: "sm_t_1"
  type: "Softmax"
  bottom: "ip_t_1"
  top: "sm_t_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip_s_1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "ts_loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "sm_s_1"
  bottom: "sm_t_1"
  top: "ts_loss"
  loss_weight: 0.05
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip_s_1"
  bottom: "label"
  top: "loss"
  loss_weight: 0.95
}
I0814 21:51:17.419040  2973 layer_factory.hpp:77] Creating layer cifar
I0814 21:51:17.419236  2973 net.cpp:91] Creating Layer cifar
I0814 21:51:17.419250  2973 net.cpp:399] cifar -> data
I0814 21:51:17.419265  2973 net.cpp:399] cifar -> label
I0814 21:51:17.419278  2973 data_transformer.cpp:25] Loading mean file from: /home/ubuntu/caffe/examples/cifar10/mean.binaryproto
I0814 21:51:17.420341  2978 db_lmdb.cpp:35] Opened lmdb /home/ubuntu/caffe/examples/cifar10/cifar10_test_lmdb
I0814 21:51:17.420495  2973 data_layer.cpp:41] output data size: 100,3,32,32
I0814 21:51:17.424458  2973 net.cpp:141] Setting up cifar
I0814 21:51:17.424484  2973 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0814 21:51:17.424492  2973 net.cpp:148] Top shape: 100 (100)
I0814 21:51:17.424499  2973 net.cpp:156] Memory required for data: 1229200
I0814 21:51:17.424504  2973 layer_factory.hpp:77] Creating layer data_cifar_0_split
I0814 21:51:17.424520  2973 net.cpp:91] Creating Layer data_cifar_0_split
I0814 21:51:17.424526  2973 net.cpp:425] data_cifar_0_split <- data
I0814 21:51:17.424540  2973 net.cpp:399] data_cifar_0_split -> data_cifar_0_split_0
I0814 21:51:17.424554  2973 net.cpp:399] data_cifar_0_split -> data_cifar_0_split_1
I0814 21:51:17.424643  2973 net.cpp:141] Setting up data_cifar_0_split
I0814 21:51:17.424664  2973 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0814 21:51:17.424672  2973 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0814 21:51:17.424677  2973 net.cpp:156] Memory required for data: 3686800
I0814 21:51:17.424685  2973 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0814 21:51:17.424710  2973 net.cpp:91] Creating Layer label_cifar_1_split
I0814 21:51:17.424717  2973 net.cpp:425] label_cifar_1_split <- label
I0814 21:51:17.424726  2973 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0814 21:51:17.424738  2973 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0814 21:51:17.424798  2973 net.cpp:141] Setting up label_cifar_1_split
I0814 21:51:17.424814  2973 net.cpp:148] Top shape: 100 (100)
I0814 21:51:17.424821  2973 net.cpp:148] Top shape: 100 (100)
I0814 21:51:17.424827  2973 net.cpp:156] Memory required for data: 3687600
I0814 21:51:17.424834  2973 layer_factory.hpp:77] Creating layer conv_s_1
I0814 21:51:17.424854  2973 net.cpp:91] Creating Layer conv_s_1
I0814 21:51:17.424860  2973 net.cpp:425] conv_s_1 <- data_cifar_0_split_0
I0814 21:51:17.424875  2973 net.cpp:399] conv_s_1 -> conv_s_1
I0814 21:51:17.426475  2973 net.cpp:141] Setting up conv_s_1
I0814 21:51:17.426497  2973 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I0814 21:51:17.426506  2973 net.cpp:156] Memory required for data: 16794800
I0814 21:51:17.426523  2973 layer_factory.hpp:77] Creating layer pool_s_1
I0814 21:51:17.426543  2973 net.cpp:91] Creating Layer pool_s_1
I0814 21:51:17.426551  2973 net.cpp:425] pool_s_1 <- conv_s_1
I0814 21:51:17.426566  2973 net.cpp:399] pool_s_1 -> pool_s_1
I0814 21:51:17.426641  2973 net.cpp:141] Setting up pool_s_1
I0814 21:51:17.426657  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.426664  2973 net.cpp:156] Memory required for data: 20071600
I0814 21:51:17.426671  2973 layer_factory.hpp:77] Creating layer relu_s_1
I0814 21:51:17.426683  2973 net.cpp:91] Creating Layer relu_s_1
I0814 21:51:17.426690  2973 net.cpp:425] relu_s_1 <- pool_s_1
I0814 21:51:17.426698  2973 net.cpp:386] relu_s_1 -> pool_s_1 (in-place)
I0814 21:51:17.426905  2973 net.cpp:141] Setting up relu_s_1
I0814 21:51:17.426926  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.426934  2973 net.cpp:156] Memory required for data: 23348400
I0814 21:51:17.426939  2973 layer_factory.hpp:77] Creating layer norm_s_1
I0814 21:51:17.426954  2973 net.cpp:91] Creating Layer norm_s_1
I0814 21:51:17.426960  2973 net.cpp:425] norm_s_1 <- pool_s_1
I0814 21:51:17.426970  2973 net.cpp:399] norm_s_1 -> norm_s_1
I0814 21:51:17.427595  2973 net.cpp:141] Setting up norm_s_1
I0814 21:51:17.427620  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.427628  2973 net.cpp:156] Memory required for data: 26625200
I0814 21:51:17.427634  2973 layer_factory.hpp:77] Creating layer conv_s_2
I0814 21:51:17.427654  2973 net.cpp:91] Creating Layer conv_s_2
I0814 21:51:17.427660  2973 net.cpp:425] conv_s_2 <- norm_s_1
I0814 21:51:17.427676  2973 net.cpp:399] conv_s_2 -> conv_s_2
I0814 21:51:17.429522  2973 net.cpp:141] Setting up conv_s_2
I0814 21:51:17.429548  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.429554  2973 net.cpp:156] Memory required for data: 29902000
I0814 21:51:17.429574  2973 layer_factory.hpp:77] Creating layer relu_s_2
I0814 21:51:17.429589  2973 net.cpp:91] Creating Layer relu_s_2
I0814 21:51:17.429596  2973 net.cpp:425] relu_s_2 <- conv_s_2
I0814 21:51:17.429606  2973 net.cpp:386] relu_s_2 -> conv_s_2 (in-place)
I0814 21:51:17.429814  2973 net.cpp:141] Setting up relu_s_2
I0814 21:51:17.429834  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.429841  2973 net.cpp:156] Memory required for data: 33178800
I0814 21:51:17.429847  2973 layer_factory.hpp:77] Creating layer pool_s_2
I0814 21:51:17.429857  2973 net.cpp:91] Creating Layer pool_s_2
I0814 21:51:17.429865  2973 net.cpp:425] pool_s_2 <- conv_s_2
I0814 21:51:17.429877  2973 net.cpp:399] pool_s_2 -> pool_s_2
I0814 21:51:17.430196  2973 net.cpp:141] Setting up pool_s_2
I0814 21:51:17.430218  2973 net.cpp:148] Top shape: 100 32 8 8 (204800)
I0814 21:51:17.430224  2973 net.cpp:156] Memory required for data: 33998000
I0814 21:51:17.430230  2973 layer_factory.hpp:77] Creating layer norm_s_2
I0814 21:51:17.430245  2973 net.cpp:91] Creating Layer norm_s_2
I0814 21:51:17.430274  2973 net.cpp:425] norm_s_2 <- pool_s_2
I0814 21:51:17.430284  2973 net.cpp:399] norm_s_2 -> norm_s_2
I0814 21:51:17.430881  2973 net.cpp:141] Setting up norm_s_2
I0814 21:51:17.430899  2973 net.cpp:148] Top shape: 100 32 8 8 (204800)
I0814 21:51:17.430907  2973 net.cpp:156] Memory required for data: 34817200
I0814 21:51:17.430912  2973 layer_factory.hpp:77] Creating layer conv_s_3
I0814 21:51:17.430934  2973 net.cpp:91] Creating Layer conv_s_3
I0814 21:51:17.430943  2973 net.cpp:425] conv_s_3 <- norm_s_2
I0814 21:51:17.430955  2973 net.cpp:399] conv_s_3 -> conv_s_3
I0814 21:51:17.433692  2973 net.cpp:141] Setting up conv_s_3
I0814 21:51:17.433714  2973 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0814 21:51:17.433722  2973 net.cpp:156] Memory required for data: 36455600
I0814 21:51:17.433737  2973 layer_factory.hpp:77] Creating layer relu_s_3
I0814 21:51:17.433753  2973 net.cpp:91] Creating Layer relu_s_3
I0814 21:51:17.433760  2973 net.cpp:425] relu_s_3 <- conv_s_3
I0814 21:51:17.433770  2973 net.cpp:386] relu_s_3 -> conv_s_3 (in-place)
I0814 21:51:17.434866  2973 net.cpp:141] Setting up relu_s_3
I0814 21:51:17.434890  2973 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0814 21:51:17.434895  2973 net.cpp:156] Memory required for data: 38094000
I0814 21:51:17.434901  2973 layer_factory.hpp:77] Creating layer pool_s_3
I0814 21:51:17.434916  2973 net.cpp:91] Creating Layer pool_s_3
I0814 21:51:17.434923  2973 net.cpp:425] pool_s_3 <- conv_s_3
I0814 21:51:17.434936  2973 net.cpp:399] pool_s_3 -> pool_s_3
I0814 21:51:17.435158  2973 net.cpp:141] Setting up pool_s_3
I0814 21:51:17.435178  2973 net.cpp:148] Top shape: 100 64 4 4 (102400)
I0814 21:51:17.435184  2973 net.cpp:156] Memory required for data: 38503600
I0814 21:51:17.435189  2973 layer_factory.hpp:77] Creating layer ip_s_1
I0814 21:51:17.435205  2973 net.cpp:91] Creating Layer ip_s_1
I0814 21:51:17.435214  2973 net.cpp:425] ip_s_1 <- pool_s_3
I0814 21:51:17.435223  2973 net.cpp:399] ip_s_1 -> ip_s_1
I0814 21:51:17.435672  2973 net.cpp:141] Setting up ip_s_1
I0814 21:51:17.435689  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.435695  2973 net.cpp:156] Memory required for data: 38507600
I0814 21:51:17.435706  2973 layer_factory.hpp:77] Creating layer ip_s_1_ip_s_1_0_split
I0814 21:51:17.435716  2973 net.cpp:91] Creating Layer ip_s_1_ip_s_1_0_split
I0814 21:51:17.435724  2973 net.cpp:425] ip_s_1_ip_s_1_0_split <- ip_s_1
I0814 21:51:17.435735  2973 net.cpp:399] ip_s_1_ip_s_1_0_split -> ip_s_1_ip_s_1_0_split_0
I0814 21:51:17.435746  2973 net.cpp:399] ip_s_1_ip_s_1_0_split -> ip_s_1_ip_s_1_0_split_1
I0814 21:51:17.435766  2973 net.cpp:399] ip_s_1_ip_s_1_0_split -> ip_s_1_ip_s_1_0_split_2
I0814 21:51:17.435835  2973 net.cpp:141] Setting up ip_s_1_ip_s_1_0_split
I0814 21:51:17.435850  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.435859  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.435866  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.435873  2973 net.cpp:156] Memory required for data: 38519600
I0814 21:51:17.435878  2973 layer_factory.hpp:77] Creating layer conv_t_1
I0814 21:51:17.435901  2973 net.cpp:91] Creating Layer conv_t_1
I0814 21:51:17.435909  2973 net.cpp:425] conv_t_1 <- data_cifar_0_split_1
I0814 21:51:17.435921  2973 net.cpp:399] conv_t_1 -> conv_t_1
I0814 21:51:17.437059  2973 net.cpp:141] Setting up conv_t_1
I0814 21:51:17.437084  2973 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I0814 21:51:17.437091  2973 net.cpp:156] Memory required for data: 51626800
I0814 21:51:17.437111  2973 layer_factory.hpp:77] Creating layer pool_t_1
I0814 21:51:17.437124  2973 net.cpp:91] Creating Layer pool_t_1
I0814 21:51:17.437131  2973 net.cpp:425] pool_t_1 <- conv_t_1
I0814 21:51:17.437144  2973 net.cpp:399] pool_t_1 -> pool_t_1
I0814 21:51:17.437212  2973 net.cpp:141] Setting up pool_t_1
I0814 21:51:17.437230  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.437237  2973 net.cpp:156] Memory required for data: 54903600
I0814 21:51:17.437242  2973 layer_factory.hpp:77] Creating layer relu_t_1
I0814 21:51:17.437269  2973 net.cpp:91] Creating Layer relu_t_1
I0814 21:51:17.437278  2973 net.cpp:425] relu_t_1 <- pool_t_1
I0814 21:51:17.437286  2973 net.cpp:386] relu_t_1 -> pool_t_1 (in-place)
I0814 21:51:17.437585  2973 net.cpp:141] Setting up relu_t_1
I0814 21:51:17.437609  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.437615  2973 net.cpp:156] Memory required for data: 58180400
I0814 21:51:17.437623  2973 layer_factory.hpp:77] Creating layer norm_t_1
I0814 21:51:17.437633  2973 net.cpp:91] Creating Layer norm_t_1
I0814 21:51:17.437639  2973 net.cpp:425] norm_t_1 <- pool_t_1
I0814 21:51:17.437654  2973 net.cpp:399] norm_t_1 -> norm_t_1
I0814 21:51:17.438194  2973 net.cpp:141] Setting up norm_t_1
I0814 21:51:17.438217  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.438225  2973 net.cpp:156] Memory required for data: 61457200
I0814 21:51:17.438230  2973 layer_factory.hpp:77] Creating layer conv_t_2
I0814 21:51:17.438251  2973 net.cpp:91] Creating Layer conv_t_2
I0814 21:51:17.438258  2973 net.cpp:425] conv_t_2 <- norm_t_1
I0814 21:51:17.438273  2973 net.cpp:399] conv_t_2 -> conv_t_2
I0814 21:51:17.440017  2973 net.cpp:141] Setting up conv_t_2
I0814 21:51:17.440042  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.440048  2973 net.cpp:156] Memory required for data: 64734000
I0814 21:51:17.440058  2973 layer_factory.hpp:77] Creating layer relu_t_2
I0814 21:51:17.440074  2973 net.cpp:91] Creating Layer relu_t_2
I0814 21:51:17.440083  2973 net.cpp:425] relu_t_2 <- conv_t_2
I0814 21:51:17.440093  2973 net.cpp:386] relu_t_2 -> conv_t_2 (in-place)
I0814 21:51:17.440402  2973 net.cpp:141] Setting up relu_t_2
I0814 21:51:17.440425  2973 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0814 21:51:17.440454  2973 net.cpp:156] Memory required for data: 68010800
I0814 21:51:17.440460  2973 layer_factory.hpp:77] Creating layer pool_t_2
I0814 21:51:17.440471  2973 net.cpp:91] Creating Layer pool_t_2
I0814 21:51:17.440479  2973 net.cpp:425] pool_t_2 <- conv_t_2
I0814 21:51:17.440488  2973 net.cpp:399] pool_t_2 -> pool_t_2
I0814 21:51:17.440804  2973 net.cpp:141] Setting up pool_t_2
I0814 21:51:17.440824  2973 net.cpp:148] Top shape: 100 32 8 8 (204800)
I0814 21:51:17.440831  2973 net.cpp:156] Memory required for data: 68830000
I0814 21:51:17.440837  2973 layer_factory.hpp:77] Creating layer norm_t_2
I0814 21:51:17.440851  2973 net.cpp:91] Creating Layer norm_t_2
I0814 21:51:17.440858  2973 net.cpp:425] norm_t_2 <- pool_t_2
I0814 21:51:17.440871  2973 net.cpp:399] norm_t_2 -> norm_t_2
I0814 21:51:17.441391  2973 net.cpp:141] Setting up norm_t_2
I0814 21:51:17.441416  2973 net.cpp:148] Top shape: 100 32 8 8 (204800)
I0814 21:51:17.441423  2973 net.cpp:156] Memory required for data: 69649200
I0814 21:51:17.441429  2973 layer_factory.hpp:77] Creating layer conv_t_3
I0814 21:51:17.441449  2973 net.cpp:91] Creating Layer conv_t_3
I0814 21:51:17.441457  2973 net.cpp:425] conv_t_3 <- norm_t_2
I0814 21:51:17.441473  2973 net.cpp:399] conv_t_3 -> conv_t_3
I0814 21:51:17.444643  2973 net.cpp:141] Setting up conv_t_3
I0814 21:51:17.444666  2973 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0814 21:51:17.444674  2973 net.cpp:156] Memory required for data: 71287600
I0814 21:51:17.444684  2973 layer_factory.hpp:77] Creating layer relu_t_3
I0814 21:51:17.444699  2973 net.cpp:91] Creating Layer relu_t_3
I0814 21:51:17.444707  2973 net.cpp:425] relu_t_3 <- conv_t_3
I0814 21:51:17.444716  2973 net.cpp:386] relu_t_3 -> conv_t_3 (in-place)
I0814 21:51:17.445026  2973 net.cpp:141] Setting up relu_t_3
I0814 21:51:17.445047  2973 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0814 21:51:17.445055  2973 net.cpp:156] Memory required for data: 72926000
I0814 21:51:17.445060  2973 layer_factory.hpp:77] Creating layer pool_t_3
I0814 21:51:17.445075  2973 net.cpp:91] Creating Layer pool_t_3
I0814 21:51:17.445082  2973 net.cpp:425] pool_t_3 <- conv_t_3
I0814 21:51:17.445092  2973 net.cpp:399] pool_t_3 -> pool_t_3
I0814 21:51:17.445314  2973 net.cpp:141] Setting up pool_t_3
I0814 21:51:17.445346  2973 net.cpp:148] Top shape: 100 64 4 4 (102400)
I0814 21:51:17.445353  2973 net.cpp:156] Memory required for data: 73335600
I0814 21:51:17.445359  2973 layer_factory.hpp:77] Creating layer ip_t_1
I0814 21:51:17.445374  2973 net.cpp:91] Creating Layer ip_t_1
I0814 21:51:17.445381  2973 net.cpp:425] ip_t_1 <- pool_t_3
I0814 21:51:17.445392  2973 net.cpp:399] ip_t_1 -> ip_t_1
I0814 21:51:17.445843  2973 net.cpp:141] Setting up ip_t_1
I0814 21:51:17.445861  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.445868  2973 net.cpp:156] Memory required for data: 73339600
I0814 21:51:17.445878  2973 layer_factory.hpp:77] Creating layer sm_s_1
I0814 21:51:17.445889  2973 net.cpp:91] Creating Layer sm_s_1
I0814 21:51:17.445895  2973 net.cpp:425] sm_s_1 <- ip_s_1_ip_s_1_0_split_0
I0814 21:51:17.445909  2973 net.cpp:399] sm_s_1 -> sm_s_1
I0814 21:51:17.446283  2973 net.cpp:141] Setting up sm_s_1
I0814 21:51:17.446305  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.446312  2973 net.cpp:156] Memory required for data: 73343600
I0814 21:51:17.446318  2973 layer_factory.hpp:77] Creating layer sm_t_1
I0814 21:51:17.446328  2973 net.cpp:91] Creating Layer sm_t_1
I0814 21:51:17.446336  2973 net.cpp:425] sm_t_1 <- ip_t_1
I0814 21:51:17.446348  2973 net.cpp:399] sm_t_1 -> sm_t_1
I0814 21:51:17.446616  2973 net.cpp:141] Setting up sm_t_1
I0814 21:51:17.446635  2973 net.cpp:148] Top shape: 100 10 (1000)
I0814 21:51:17.446641  2973 net.cpp:156] Memory required for data: 73347600
I0814 21:51:17.446647  2973 layer_factory.hpp:77] Creating layer accuracy
I0814 21:51:17.446665  2973 net.cpp:91] Creating Layer accuracy
I0814 21:51:17.446671  2973 net.cpp:425] accuracy <- ip_s_1_ip_s_1_0_split_1
I0814 21:51:17.446679  2973 net.cpp:425] accuracy <- label_cifar_1_split_0
I0814 21:51:17.446692  2973 net.cpp:399] accuracy -> accuracy
I0814 21:51:17.446712  2973 net.cpp:141] Setting up accuracy
I0814 21:51:17.446725  2973 net.cpp:148] Top shape: (1)
I0814 21:51:17.446732  2973 net.cpp:156] Memory required for data: 73347604
I0814 21:51:17.446738  2973 layer_factory.hpp:77] Creating layer ts_loss
I0814 21:51:17.446753  2973 net.cpp:91] Creating Layer ts_loss
I0814 21:51:17.446759  2973 net.cpp:425] ts_loss <- sm_s_1
I0814 21:51:17.446768  2973 net.cpp:425] ts_loss <- sm_t_1
I0814 21:51:17.446775  2973 net.cpp:399] ts_loss -> ts_loss
I0814 21:51:17.446856  2973 net.cpp:141] Setting up ts_loss
I0814 21:51:17.446874  2973 net.cpp:148] Top shape: (1)
I0814 21:51:17.446880  2973 net.cpp:151]     with loss weight 0.05
I0814 21:51:17.446900  2973 net.cpp:156] Memory required for data: 73347608
I0814 21:51:17.446907  2973 layer_factory.hpp:77] Creating layer loss
I0814 21:51:17.446920  2973 net.cpp:91] Creating Layer loss
I0814 21:51:17.446928  2973 net.cpp:425] loss <- ip_s_1_ip_s_1_0_split_2
I0814 21:51:17.446935  2973 net.cpp:425] loss <- label_cifar_1_split_1
I0814 21:51:17.446947  2973 net.cpp:399] loss -> loss
I0814 21:51:17.446962  2973 layer_factory.hpp:77] Creating layer loss
I0814 21:51:17.447360  2973 net.cpp:141] Setting up loss
I0814 21:51:17.447381  2973 net.cpp:148] Top shape: (1)
I0814 21:51:17.447388  2973 net.cpp:151]     with loss weight 0.95
I0814 21:51:17.447399  2973 net.cpp:156] Memory required for data: 73347612
I0814 21:51:17.447405  2973 net.cpp:217] loss needs backward computation.
I0814 21:51:17.447413  2973 net.cpp:217] ts_loss needs backward computation.
I0814 21:51:17.447419  2973 net.cpp:219] accuracy does not need backward computation.
I0814 21:51:17.447427  2973 net.cpp:219] sm_t_1 does not need backward computation.
I0814 21:51:17.447432  2973 net.cpp:217] sm_s_1 needs backward computation.
I0814 21:51:17.447438  2973 net.cpp:219] ip_t_1 does not need backward computation.
I0814 21:51:17.447444  2973 net.cpp:219] pool_t_3 does not need backward computation.
I0814 21:51:17.447450  2973 net.cpp:219] relu_t_3 does not need backward computation.
I0814 21:51:17.447456  2973 net.cpp:219] conv_t_3 does not need backward computation.
I0814 21:51:17.447463  2973 net.cpp:219] norm_t_2 does not need backward computation.
I0814 21:51:17.447481  2973 net.cpp:219] pool_t_2 does not need backward computation.
I0814 21:51:17.447489  2973 net.cpp:219] relu_t_2 does not need backward computation.
I0814 21:51:17.447494  2973 net.cpp:219] conv_t_2 does not need backward computation.
I0814 21:51:17.447499  2973 net.cpp:219] norm_t_1 does not need backward computation.
I0814 21:51:17.447505  2973 net.cpp:219] relu_t_1 does not need backward computation.
I0814 21:51:17.447511  2973 net.cpp:219] pool_t_1 does not need backward computation.
I0814 21:51:17.447517  2973 net.cpp:219] conv_t_1 does not need backward computation.
I0814 21:51:17.447527  2973 net.cpp:217] ip_s_1_ip_s_1_0_split needs backward computation.
I0814 21:51:17.447533  2973 net.cpp:217] ip_s_1 needs backward computation.
I0814 21:51:17.447540  2973 net.cpp:217] pool_s_3 needs backward computation.
I0814 21:51:17.447546  2973 net.cpp:217] relu_s_3 needs backward computation.
I0814 21:51:17.447551  2973 net.cpp:217] conv_s_3 needs backward computation.
I0814 21:51:17.447557  2973 net.cpp:217] norm_s_2 needs backward computation.
I0814 21:51:17.447564  2973 net.cpp:217] pool_s_2 needs backward computation.
I0814 21:51:17.447569  2973 net.cpp:217] relu_s_2 needs backward computation.
I0814 21:51:17.447576  2973 net.cpp:217] conv_s_2 needs backward computation.
I0814 21:51:17.447582  2973 net.cpp:217] norm_s_1 needs backward computation.
I0814 21:51:17.447587  2973 net.cpp:217] relu_s_1 needs backward computation.
I0814 21:51:17.447593  2973 net.cpp:217] pool_s_1 needs backward computation.
I0814 21:51:17.447599  2973 net.cpp:217] conv_s_1 needs backward computation.
I0814 21:51:17.447607  2973 net.cpp:219] label_cifar_1_split does not need backward computation.
I0814 21:51:17.447613  2973 net.cpp:219] data_cifar_0_split does not need backward computation.
I0814 21:51:17.447619  2973 net.cpp:219] cifar does not need backward computation.
I0814 21:51:17.447625  2973 net.cpp:261] This network produces output accuracy
I0814 21:51:17.447631  2973 net.cpp:261] This network produces output loss
I0814 21:51:17.447638  2973 net.cpp:261] This network produces output ts_loss
I0814 21:51:17.447676  2973 net.cpp:274] Network initialization done.
I0814 21:51:17.447841  2973 solver.cpp:60] Solver scaffolding done.
I0814 21:51:17.448484  2973 caffe.cpp:219] Starting Optimization
I0814 21:51:17.448500  2973 solver.cpp:279] Solving CIFAR10_full
I0814 21:51:17.448508  2973 solver.cpp:280] Learning Rate Policy: step
I0814 21:51:17.449087  2973 solver.cpp:337] Iteration 0, Testing net (#0)
I0814 21:51:19.039970  2973 solver.cpp:404]     Test net output #0: accuracy = 0.1168
I0814 21:51:19.040017  2973 solver.cpp:404]     Test net output #1: loss = 2.30257 (* 0.95 = 2.18744 loss)
I0814 21:51:19.040025  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.34395 (* 0.05 = 0.367197 loss)
I0814 21:51:19.057874  2973 solver.cpp:228] Iteration 0, loss = 2.55463
I0814 21:51:19.057904  2973 solver.cpp:244]     Train net output #0: loss = 2.30256 (* 0.95 = 2.18743 loss)
I0814 21:51:19.057914  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.34395 (* 0.05 = 0.367197 loss)
I0814 21:51:19.057937  2973 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0814 21:52:00.030866  2973 solver.cpp:337] Iteration 1000, Testing net (#0)
I0814 21:52:01.514931  2973 solver.cpp:404]     Test net output #0: accuracy = 0.5249
I0814 21:52:01.514979  2973 solver.cpp:404]     Test net output #1: loss = 1.3437 (* 0.95 = 1.27652 loss)
I0814 21:52:01.514987  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.37411 (* 0.05 = 0.368705 loss)
I0814 21:52:01.530056  2973 solver.cpp:228] Iteration 1000, loss = 1.67743
I0814 21:52:01.530102  2973 solver.cpp:244]     Train net output #0: loss = 1.37778 (* 0.95 = 1.30889 loss)
I0814 21:52:01.530109  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.37081 (* 0.05 = 0.368541 loss)
I0814 21:52:01.530117  2973 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0814 21:52:42.515740  2973 solver.cpp:337] Iteration 2000, Testing net (#0)
I0814 21:52:44.010411  2973 solver.cpp:404]     Test net output #0: accuracy = 0.5923
I0814 21:52:44.010455  2973 solver.cpp:404]     Test net output #1: loss = 1.16452 (* 0.95 = 1.1063 loss)
I0814 21:52:44.010463  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.38114 (* 0.05 = 0.369057 loss)
I0814 21:52:44.025720  2973 solver.cpp:228] Iteration 2000, loss = 1.46659
I0814 21:52:44.025761  2973 solver.cpp:244]     Train net output #0: loss = 1.15539 (* 0.95 = 1.09762 loss)
I0814 21:52:44.025770  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.3794 (* 0.05 = 0.36897 loss)
I0814 21:52:44.025777  2973 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0814 21:53:25.133852  2973 solver.cpp:337] Iteration 3000, Testing net (#0)
I0814 21:53:26.636298  2973 solver.cpp:404]     Test net output #0: accuracy = 0.6165
I0814 21:53:26.636345  2973 solver.cpp:404]     Test net output #1: loss = 1.06198 (* 0.95 = 1.00888 loss)
I0814 21:53:26.636353  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.38852 (* 0.05 = 0.369426 loss)
I0814 21:53:26.651504  2973 solver.cpp:228] Iteration 3000, loss = 1.30434
I0814 21:53:26.651532  2973 solver.cpp:244]     Train net output #0: loss = 0.984184 (* 0.95 = 0.934975 loss)
I0814 21:53:26.651540  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.38738 (* 0.05 = 0.369369 loss)
I0814 21:53:26.651549  2973 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0814 21:54:07.914391  2973 solver.cpp:337] Iteration 4000, Testing net (#0)
I0814 21:54:09.417717  2973 solver.cpp:404]     Test net output #0: accuracy = 0.6494
I0814 21:54:09.417764  2973 solver.cpp:404]     Test net output #1: loss = 0.990098 (* 0.95 = 0.940593 loss)
I0814 21:54:09.417773  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.39378 (* 0.05 = 0.369689 loss)
I0814 21:54:09.432942  2973 solver.cpp:228] Iteration 4000, loss = 1.19436
I0814 21:54:09.432971  2973 solver.cpp:244]     Train net output #0: loss = 0.868159 (* 0.95 = 0.824751 loss)
I0814 21:54:09.432977  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.3922 (* 0.05 = 0.36961 loss)
I0814 21:54:09.432986  2973 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0814 21:54:50.831576  2973 solver.cpp:337] Iteration 5000, Testing net (#0)
I0814 21:54:52.337467  2973 solver.cpp:404]     Test net output #0: accuracy = 0.6761
I0814 21:54:52.337515  2973 solver.cpp:404]     Test net output #1: loss = 0.924935 (* 0.95 = 0.878689 loss)
I0814 21:54:52.337523  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.39737 (* 0.05 = 0.369869 loss)
I0814 21:54:52.352679  2973 solver.cpp:228] Iteration 5000, loss = 1.12386
I0814 21:54:52.352705  2973 solver.cpp:244]     Train net output #0: loss = 0.793776 (* 0.95 = 0.754087 loss)
I0814 21:54:52.352712  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.39554 (* 0.05 = 0.369777 loss)
I0814 21:54:52.352720  2973 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0814 21:55:33.777657  2973 solver.cpp:337] Iteration 6000, Testing net (#0)
I0814 21:55:35.285118  2973 solver.cpp:404]     Test net output #0: accuracy = 0.6965
I0814 21:55:35.285166  2973 solver.cpp:404]     Test net output #1: loss = 0.876152 (* 0.95 = 0.832344 loss)
I0814 21:55:35.285173  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.40038 (* 0.05 = 0.370019 loss)
I0814 21:55:35.300344  2973 solver.cpp:228] Iteration 6000, loss = 1.07023
I0814 21:55:35.300370  2973 solver.cpp:244]     Train net output #0: loss = 0.737168 (* 0.95 = 0.700309 loss)
I0814 21:55:35.300379  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.39851 (* 0.05 = 0.369926 loss)
I0814 21:55:35.300385  2973 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0814 21:56:16.682272  2973 solver.cpp:337] Iteration 7000, Testing net (#0)
I0814 21:56:18.188558  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7085
I0814 21:56:18.188603  2973 solver.cpp:404]     Test net output #1: loss = 0.837078 (* 0.95 = 0.795224 loss)
I0814 21:56:18.188611  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.40287 (* 0.05 = 0.370143 loss)
I0814 21:56:18.203914  2973 solver.cpp:228] Iteration 7000, loss = 1.03749
I0814 21:56:18.203946  2973 solver.cpp:244]     Train net output #0: loss = 0.702566 (* 0.95 = 0.667438 loss)
I0814 21:56:18.203954  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40109 (* 0.05 = 0.370054 loss)
I0814 21:56:18.203961  2973 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0814 21:56:59.566699  2973 solver.cpp:337] Iteration 8000, Testing net (#0)
I0814 21:57:01.073448  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7188
I0814 21:57:01.073494  2973 solver.cpp:404]     Test net output #1: loss = 0.809569 (* 0.95 = 0.76909 loss)
I0814 21:57:01.073503  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.40457 (* 0.05 = 0.370228 loss)
I0814 21:57:01.088625  2973 solver.cpp:228] Iteration 8000, loss = 1.01137
I0814 21:57:01.088651  2973 solver.cpp:244]     Train net output #0: loss = 0.674982 (* 0.95 = 0.641233 loss)
I0814 21:57:01.088660  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40279 (* 0.05 = 0.37014 loss)
I0814 21:57:01.088666  2973 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0814 21:57:42.524148  2973 solver.cpp:337] Iteration 9000, Testing net (#0)
I0814 21:57:44.031343  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7276
I0814 21:57:44.031390  2973 solver.cpp:404]     Test net output #1: loss = 0.789494 (* 0.95 = 0.75002 loss)
I0814 21:57:44.031399  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.40585 (* 0.05 = 0.370293 loss)
I0814 21:57:44.046574  2973 solver.cpp:228] Iteration 9000, loss = 0.98157
I0814 21:57:44.046603  2973 solver.cpp:244]     Train net output #0: loss = 0.643546 (* 0.95 = 0.611369 loss)
I0814 21:57:44.046610  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40403 (* 0.05 = 0.370201 loss)
I0814 21:57:44.046617  2973 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0814 21:58:25.488792  2973 solver.cpp:454] Snapshotting to binary proto file ts_cifar10/_iter_10000.caffemodel
I0814 21:58:25.519832  2973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ts_cifar10/_iter_10000.solverstate
I0814 21:58:25.521478  2973 solver.cpp:337] Iteration 10000, Testing net (#0)
I0814 21:58:27.003140  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7328
I0814 21:58:27.003190  2973 solver.cpp:404]     Test net output #1: loss = 0.769464 (* 0.95 = 0.730991 loss)
I0814 21:58:27.003199  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.4071 (* 0.05 = 0.370355 loss)
I0814 21:58:27.018393  2973 solver.cpp:228] Iteration 10000, loss = 0.95941
I0814 21:58:27.018421  2973 solver.cpp:244]     Train net output #0: loss = 0.620158 (* 0.95 = 0.58915 loss)
I0814 21:58:27.018429  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40519 (* 0.05 = 0.37026 loss)
I0814 21:58:27.018436  2973 sgd_solver.cpp:106] Iteration 10000, lr = 0.0005
I0814 21:59:08.408609  2973 solver.cpp:337] Iteration 11000, Testing net (#0)
I0814 21:59:09.916497  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7366
I0814 21:59:09.916543  2973 solver.cpp:404]     Test net output #1: loss = 0.752249 (* 0.95 = 0.714637 loss)
I0814 21:59:09.916550  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.40837 (* 0.05 = 0.370419 loss)
I0814 21:59:09.931705  2973 solver.cpp:228] Iteration 11000, loss = 0.945073
I0814 21:59:09.931731  2973 solver.cpp:244]     Train net output #0: loss = 0.604925 (* 0.95 = 0.574679 loss)
I0814 21:59:09.931740  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40789 (* 0.05 = 0.370394 loss)
I0814 21:59:09.931746  2973 sgd_solver.cpp:106] Iteration 11000, lr = 0.0005
I0814 21:59:51.319082  2973 solver.cpp:337] Iteration 12000, Testing net (#0)
I0814 21:59:52.826473  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7399
I0814 21:59:52.826524  2973 solver.cpp:404]     Test net output #1: loss = 0.743473 (* 0.95 = 0.7063 loss)
I0814 21:59:52.826532  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.40864 (* 0.05 = 0.370432 loss)
I0814 21:59:52.841754  2973 solver.cpp:228] Iteration 12000, loss = 0.930562
I0814 21:59:52.841791  2973 solver.cpp:244]     Train net output #0: loss = 0.589646 (* 0.95 = 0.560163 loss)
I0814 21:59:52.841799  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40797 (* 0.05 = 0.370398 loss)
I0814 21:59:52.841806  2973 sgd_solver.cpp:106] Iteration 12000, lr = 0.0005
I0814 22:00:34.302966  2973 solver.cpp:337] Iteration 13000, Testing net (#0)
I0814 22:00:35.811208  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7427
I0814 22:00:35.811255  2973 solver.cpp:404]     Test net output #1: loss = 0.735925 (* 0.95 = 0.699129 loss)
I0814 22:00:35.811264  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.40899 (* 0.05 = 0.370449 loss)
I0814 22:00:35.826396  2973 solver.cpp:228] Iteration 13000, loss = 0.921448
I0814 22:00:35.826426  2973 solver.cpp:244]     Train net output #0: loss = 0.580037 (* 0.95 = 0.551035 loss)
I0814 22:00:35.826432  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40826 (* 0.05 = 0.370413 loss)
I0814 22:00:35.826439  2973 sgd_solver.cpp:106] Iteration 13000, lr = 0.0005
I0814 22:01:17.292778  2973 solver.cpp:337] Iteration 14000, Testing net (#0)
I0814 22:01:18.800842  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7432
I0814 22:01:18.800886  2973 solver.cpp:404]     Test net output #1: loss = 0.729599 (* 0.95 = 0.693119 loss)
I0814 22:01:18.800894  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.40941 (* 0.05 = 0.370471 loss)
I0814 22:01:18.816052  2973 solver.cpp:228] Iteration 14000, loss = 0.913677
I0814 22:01:18.816085  2973 solver.cpp:244]     Train net output #0: loss = 0.571844 (* 0.95 = 0.543252 loss)
I0814 22:01:18.816093  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40849 (* 0.05 = 0.370425 loss)
I0814 22:01:18.816100  2973 sgd_solver.cpp:106] Iteration 14000, lr = 0.0005
I0814 22:02:00.216153  2973 solver.cpp:337] Iteration 15000, Testing net (#0)
I0814 22:02:01.724493  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7462
I0814 22:02:01.724541  2973 solver.cpp:404]     Test net output #1: loss = 0.723605 (* 0.95 = 0.687425 loss)
I0814 22:02:01.724550  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.40969 (* 0.05 = 0.370484 loss)
I0814 22:02:01.739833  2973 solver.cpp:228] Iteration 15000, loss = 0.908249
I0814 22:02:01.739866  2973 solver.cpp:244]     Train net output #0: loss = 0.566123 (* 0.95 = 0.537817 loss)
I0814 22:02:01.739873  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40865 (* 0.05 = 0.370432 loss)
I0814 22:02:01.739881  2973 sgd_solver.cpp:106] Iteration 15000, lr = 0.0005
I0814 22:02:43.113708  2973 solver.cpp:337] Iteration 16000, Testing net (#0)
I0814 22:02:44.619562  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7487
I0814 22:02:44.619609  2973 solver.cpp:404]     Test net output #1: loss = 0.71756 (* 0.95 = 0.681682 loss)
I0814 22:02:44.619617  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.40994 (* 0.05 = 0.370497 loss)
I0814 22:02:44.634805  2973 solver.cpp:228] Iteration 16000, loss = 0.901749
I0814 22:02:44.634834  2973 solver.cpp:244]     Train net output #0: loss = 0.559276 (* 0.95 = 0.531313 loss)
I0814 22:02:44.634841  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40872 (* 0.05 = 0.370436 loss)
I0814 22:02:44.634847  2973 sgd_solver.cpp:106] Iteration 16000, lr = 0.0005
I0814 22:03:26.065711  2973 solver.cpp:337] Iteration 17000, Testing net (#0)
I0814 22:03:27.573985  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7496
I0814 22:03:27.574033  2973 solver.cpp:404]     Test net output #1: loss = 0.712899 (* 0.95 = 0.677254 loss)
I0814 22:03:27.574041  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.41029 (* 0.05 = 0.370515 loss)
I0814 22:03:27.589243  2973 solver.cpp:228] Iteration 17000, loss = 0.895988
I0814 22:03:27.589274  2973 solver.cpp:244]     Train net output #0: loss = 0.553197 (* 0.95 = 0.525537 loss)
I0814 22:03:27.589282  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40902 (* 0.05 = 0.370451 loss)
I0814 22:03:27.589289  2973 sgd_solver.cpp:106] Iteration 17000, lr = 0.0005
I0814 22:04:09.043875  2973 solver.cpp:337] Iteration 18000, Testing net (#0)
I0814 22:04:10.553014  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7503
I0814 22:04:10.553061  2973 solver.cpp:404]     Test net output #1: loss = 0.708011 (* 0.95 = 0.672611 loss)
I0814 22:04:10.553068  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.41066 (* 0.05 = 0.370533 loss)
I0814 22:04:10.568316  2973 solver.cpp:228] Iteration 18000, loss = 0.891883
I0814 22:04:10.568344  2973 solver.cpp:244]     Train net output #0: loss = 0.548863 (* 0.95 = 0.52142 loss)
I0814 22:04:10.568352  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40926 (* 0.05 = 0.370463 loss)
I0814 22:04:10.568359  2973 sgd_solver.cpp:106] Iteration 18000, lr = 0.0005
I0814 22:04:51.972878  2973 solver.cpp:337] Iteration 19000, Testing net (#0)
I0814 22:04:53.482028  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7512
I0814 22:04:53.482076  2973 solver.cpp:404]     Test net output #1: loss = 0.70381 (* 0.95 = 0.668619 loss)
I0814 22:04:53.482084  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.411 (* 0.05 = 0.37055 loss)
I0814 22:04:53.497288  2973 solver.cpp:228] Iteration 19000, loss = 0.887606
I0814 22:04:53.497316  2973 solver.cpp:244]     Train net output #0: loss = 0.544347 (* 0.95 = 0.51713 loss)
I0814 22:04:53.497324  2973 solver.cpp:244]     Train net output #1: ts_loss = 7.40952 (* 0.05 = 0.370476 loss)
I0814 22:04:53.497331  2973 sgd_solver.cpp:106] Iteration 19000, lr = 0.0005
I0814 22:05:34.882277  2973 solver.cpp:454] Snapshotting to binary proto file ts_cifar10/_iter_20000.caffemodel
I0814 22:05:34.911399  2973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ts_cifar10/_iter_20000.solverstate
I0814 22:05:34.927588  2973 solver.cpp:317] Iteration 20000, loss = 0.885446
I0814 22:05:34.927619  2973 solver.cpp:337] Iteration 20000, Testing net (#0)
I0814 22:05:36.409059  2973 solver.cpp:404]     Test net output #0: accuracy = 0.7523
I0814 22:05:36.409107  2973 solver.cpp:404]     Test net output #1: loss = 0.701642 (* 0.95 = 0.66656 loss)
I0814 22:05:36.409116  2973 solver.cpp:404]     Test net output #2: ts_loss = 7.41132 (* 0.05 = 0.370566 loss)
I0814 22:05:36.409121  2973 solver.cpp:322] Optimization Done.
I0814 22:05:36.409126  2973 caffe.cpp:222] Optimization Done.
