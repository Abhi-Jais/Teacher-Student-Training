{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run teacher-student training with the cifar10 dataset.\n",
    "\n",
    "The teacher model is the default cifar10_train_test.prototxt model with the layer names adjusted to match up with the teacher-student model. Here are the changes to the solver:\n",
    "\n",
    "lr policy changed from fixed to step\n",
    "gamma of 0.1 inserted\n",
    "stepsize of 20000 inserted\n",
    "max_iter raised to 100000\n",
    "\n",
    "The snapshot of the model at iteration 100000 is used for training the ts_cifar10. Its accuracy has plateaud at 80.5%.\n",
    "\n",
    "For the first ts_training we cut out the traditional softmax loss label and train only using the teacher soft labels.\n",
    "\n",
    "We put the teacher and student labels through softmax layers, then feed those two into a cross-entropy loss layer.\n",
    "\n",
    "The teacher-student model was trained for 100000 iterations using a gamma of 0.5 with a stepsize of 10000. The accuracy plateaud at around 67.5% for the last 30,000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prototxt of the cifar10 teacher-student model\n",
    "\n",
    "# name: \"CIFAR10_full\"\n",
    "# layer {\n",
    "#   name: \"cifar\"\n",
    "#   type: \"Data\"\n",
    "#   top: \"data\"\n",
    "#   top: \"label\"\n",
    "#   include {\n",
    "#     phase: TRAIN\n",
    "#   }\n",
    "#   transform_param {\n",
    "#     mean_file: \"/opt/caffe/examples/cifar10/mean.binaryproto\"\n",
    "#   }\n",
    "#   data_param {\n",
    "#     source: \"/opt/caffe/examples/cifar10/cifar10_train_lmdb\"\n",
    "#     batch_size: 100\n",
    "#     backend: LMDB\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"cifar\"\n",
    "#   type: \"Data\"\n",
    "#   top: \"data\"\n",
    "#   top: \"label\"\n",
    "#   include {\n",
    "#     phase: TEST\n",
    "#   }\n",
    "#   transform_param {\n",
    "#     mean_file: \"/opt/caffe/examples/cifar10/mean.binaryproto\"\n",
    "#   }\n",
    "#   data_param {\n",
    "#     source: \"/opt/caffe/examples/cifar10/cifar10_test_lmdb\"\n",
    "#     batch_size: 100\n",
    "#     backend: LMDB\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"conv_s_1\"\n",
    "#   type: \"Convolution\"\n",
    "#   bottom: \"data\"\n",
    "#   top: \"conv_s_1\"\n",
    "#   param {\n",
    "#     lr_mult: 1\n",
    "#   }\n",
    "#   param {\n",
    "#     lr_mult: 2\n",
    "#   }\n",
    "#   convolution_param {\n",
    "#     num_output: 32\n",
    "#     pad: 2\n",
    "#     kernel_size: 5\n",
    "#     stride: 1\n",
    "#     weight_filler {\n",
    "#       type: \"gaussian\"\n",
    "#       std: 0.0001\n",
    "#     }\n",
    "#     bias_filler {\n",
    "#       type: \"constant\"\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"pool_s_1\"\n",
    "#   type: \"Pooling\"\n",
    "#   bottom: \"conv_s_1\"\n",
    "#   top: \"pool_s_1\"\n",
    "#   pooling_param {\n",
    "#     pool: MAX\n",
    "#     kernel_size: 3\n",
    "#     stride: 2\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"relu_s_1\"\n",
    "#   type: \"ReLU\"\n",
    "#   bottom: \"pool_s_1\"\n",
    "#   top: \"pool_s_1\"\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"norm_s_1\"\n",
    "#   type: \"LRN\"\n",
    "#   bottom: \"pool_s_1\"\n",
    "#   top: \"norm_s_1\"\n",
    "#   lrn_param {\n",
    "#     local_size: 3\n",
    "#     alpha: 5e-05\n",
    "#     beta: 0.75\n",
    "#     norm_region: WITHIN_CHANNEL\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"conv_s_2\"\n",
    "#   type: \"Convolution\"\n",
    "#   bottom: \"norm_s_1\"\n",
    "#   top: \"conv_s_2\"\n",
    "#   param {\n",
    "#     lr_mult: 1\n",
    "#   }\n",
    "#   param {\n",
    "#     lr_mult: 2\n",
    "#   }\n",
    "#   convolution_param {\n",
    "#     num_output: 32\n",
    "#     pad: 2\n",
    "#     kernel_size: 5\n",
    "#     stride: 1\n",
    "#     weight_filler {\n",
    "#       type: \"gaussian\"\n",
    "#       std: 0.01\n",
    "#     }\n",
    "#     bias_filler {\n",
    "#       type: \"constant\"\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"relu_s_2\"\n",
    "#   type: \"ReLU\"\n",
    "#   bottom: \"conv_s_2\"\n",
    "#   top: \"conv_s_2\"\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"pool_s_2\"\n",
    "#   type: \"Pooling\"\n",
    "#   bottom: \"conv_s_2\"\n",
    "#   top: \"pool_s_2\"\n",
    "#   pooling_param {\n",
    "#     pool: AVE\n",
    "#     kernel_size: 3\n",
    "#     stride: 2\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"norm_s_2\"\n",
    "#   type: \"LRN\"\n",
    "#   bottom: \"pool_s_2\"\n",
    "#   top: \"norm_s_2\"\n",
    "#   lrn_param {\n",
    "#     local_size: 3\n",
    "#     alpha: 5e-05\n",
    "#     beta: 0.75\n",
    "#     norm_region: WITHIN_CHANNEL\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"conv_s_3\"\n",
    "#   type: \"Convolution\"\n",
    "#   bottom: \"norm_s_2\"\n",
    "#   top: \"conv_s_3\"\n",
    "#   param {\n",
    "#     lr_mult: 1\n",
    "#   }\n",
    "#   param {\n",
    "#     lr_mult: 2\n",
    "#   }\n",
    "#   convolution_param {\n",
    "#     num_output: 64\n",
    "#     pad: 2\n",
    "#     kernel_size: 5\n",
    "#     stride: 1\n",
    "#     weight_filler {\n",
    "#       type: \"gaussian\"\n",
    "#       std: 0.01\n",
    "#     }\n",
    "#     bias_filler {\n",
    "#       type: \"constant\"\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"relu_s_3\"\n",
    "#   type: \"ReLU\"\n",
    "#   bottom: \"conv_s_3\"\n",
    "#   top: \"conv_s_3\"\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"pool_s_3\"\n",
    "#   type: \"Pooling\"\n",
    "#   bottom: \"conv_s_3\"\n",
    "#   top: \"pool_s_3\"\n",
    "#   pooling_param {\n",
    "#     pool: AVE\n",
    "#     kernel_size: 3\n",
    "#     stride: 2\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"ip_s_1\"\n",
    "#   type: \"InnerProduct\"\n",
    "#   bottom: \"pool_s_3\"\n",
    "#   top: \"ip_s_1\"\n",
    "#   param {\n",
    "#     lr_mult: 1\n",
    "#     decay_mult: 250\n",
    "#   }\n",
    "#   param {\n",
    "#     lr_mult: 2\n",
    "#     decay_mult: 0\n",
    "#   }\n",
    "#   inner_product_param {\n",
    "#     num_output: 10\n",
    "#     weight_filler {\n",
    "#       type: \"gaussian\"\n",
    "#       std: 0.01\n",
    "#     }\n",
    "#     bias_filler {\n",
    "#       type: \"constant\"\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"conv_t_1\"\n",
    "#   type: \"Convolution\"\n",
    "#   bottom: \"data\"\n",
    "#   top: \"conv_t_1\"\n",
    "#   param {\n",
    "#     lr_mult: 0\n",
    "#   }\n",
    "#   param {\n",
    "#     lr_mult: 0\n",
    "#   }\n",
    "#   convolution_param {\n",
    "#     num_output: 32\n",
    "#     pad: 2\n",
    "#     kernel_size: 5\n",
    "#     stride: 1\n",
    "#     weight_filler {\n",
    "#       type: \"gaussian\"\n",
    "#       std: 0.0001\n",
    "#     }\n",
    "#     bias_filler {\n",
    "#       type: \"constant\"\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"pool_t_1\"\n",
    "#   type: \"Pooling\"\n",
    "#   bottom: \"conv_t_1\"\n",
    "#   top: \"pool_t_1\"\n",
    "#   pooling_param {\n",
    "#     pool: MAX\n",
    "#     kernel_size: 3\n",
    "#     stride: 2\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"relu_t_1\"\n",
    "#   type: \"ReLU\"\n",
    "#   bottom: \"pool_t_1\"\n",
    "#   top: \"pool_t_1\"\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"norm_t_1\"\n",
    "#   type: \"LRN\"\n",
    "#   bottom: \"pool_t_1\"\n",
    "#   top: \"norm_t_1\"\n",
    "#   lrn_param {\n",
    "#     local_size: 3\n",
    "#     alpha: 5e-05\n",
    "#     beta: 0.75\n",
    "#     norm_region: WITHIN_CHANNEL\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"conv_t_2\"\n",
    "#   type: \"Convolution\"\n",
    "#   bottom: \"norm_t_1\"\n",
    "#   top: \"conv_t_2\"\n",
    "#   param {\n",
    "#     lr_mult: 0\n",
    "#   }\n",
    "#   param {\n",
    "#     lr_mult: 0\n",
    "#   }\n",
    "#   convolution_param {\n",
    "#     num_output: 32\n",
    "#     pad: 2\n",
    "#     kernel_size: 5\n",
    "#     stride: 1\n",
    "#     weight_filler {\n",
    "#       type: \"gaussian\"\n",
    "#       std: 0.01\n",
    "#     }\n",
    "#     bias_filler {\n",
    "#       type: \"constant\"\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"relu_t_2\"\n",
    "#   type: \"ReLU\"\n",
    "#   bottom: \"conv_t_2\"\n",
    "#   top: \"conv_t_2\"\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"pool_t_2\"\n",
    "#   type: \"Pooling\"\n",
    "#   bottom: \"conv_t_2\"\n",
    "#   top: \"pool_t_2\"\n",
    "#   pooling_param {\n",
    "#     pool: AVE\n",
    "#     kernel_size: 3\n",
    "#     stride: 2\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"norm_t_2\"\n",
    "#   type: \"LRN\"\n",
    "#   bottom: \"pool_t_2\"\n",
    "#   top: \"norm_t_2\"\n",
    "#   lrn_param {\n",
    "#     local_size: 3\n",
    "#     alpha: 5e-05\n",
    "#     beta: 0.75\n",
    "#     norm_region: WITHIN_CHANNEL\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"conv_t_3\"\n",
    "#   type: \"Convolution\"\n",
    "#   bottom: \"norm_t_2\"\n",
    "#   top: \"conv_t_3\"\n",
    "#   param {\n",
    "#     lr_mult: 0\n",
    "#   }\n",
    "#   param {\n",
    "#     lr_mult: 0\n",
    "#   }\n",
    "#   convolution_param {\n",
    "#     num_output: 64\n",
    "#     pad: 2\n",
    "#     kernel_size: 5\n",
    "#     stride: 1\n",
    "#     weight_filler {\n",
    "#       type: \"gaussian\"\n",
    "#       std: 0.01\n",
    "#     }\n",
    "#     bias_filler {\n",
    "#       type: \"constant\"\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"relu_t_3\"\n",
    "#   type: \"ReLU\"\n",
    "#   bottom: \"conv_t_3\"\n",
    "#   top: \"conv_t_3\"\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"pool_t_3\"\n",
    "#   type: \"Pooling\"\n",
    "#   bottom: \"conv_t_3\"\n",
    "#   top: \"pool_t_3\"\n",
    "#   pooling_param {\n",
    "#     pool: AVE\n",
    "#     kernel_size: 3\n",
    "#     stride: 2\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"ip_t_1\"\n",
    "#   type: \"InnerProduct\"\n",
    "#   bottom: \"pool_t_3\"\n",
    "#   top: \"ip_t_1\"\n",
    "#   param {\n",
    "#     lr_mult: 0\n",
    "#   }\n",
    "#   param {\n",
    "#     lr_mult: 0\n",
    "#   }\n",
    "#   inner_product_param {\n",
    "#     num_output: 10\n",
    "#     weight_filler {\n",
    "#       type: \"gaussian\"\n",
    "#       std: 0.01\n",
    "#     }\n",
    "#     bias_filler {\n",
    "#       type: \"constant\"\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"sm_s_1\"\n",
    "#   type: \"Softmax\"\n",
    "#   bottom: \"ip_s_1\"\n",
    "#   top: \"sm_s_1\"\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"sm_t_1\"\n",
    "#   type: \"Softmax\"\n",
    "#   bottom: \"ip_t_1\"\n",
    "#   top: \"sm_t_1\"\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"accuracy\"\n",
    "#   type: \"Accuracy\"\n",
    "#   bottom: \"ip_s_1\"\n",
    "#   bottom: \"label\"\n",
    "#   top: \"accuracy\"\n",
    "#   include {\n",
    "#     phase: TEST\n",
    "#   }\n",
    "# }\n",
    "# layer {\n",
    "#   name: \"ts_loss\"\n",
    "#   type: \"SigmoidCrossEntropyLoss\"\n",
    "#   bottom: \"sm_s_1\"\n",
    "#   bottom: \"sm_t_1\"\n",
    "#   top: \"ts_loss\"\n",
    "#   loss_weight: 1\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training with both soft and hard labels, we tack on the following layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer {\n",
    "    name: \"loss\"\n",
    "    type: \"SoftmaxWithLoss\"\n",
    "    bottom: \"ip_s_1\"\n",
    "    bottom: \"label\"\n",
    "    top: \"loss\"\n",
    "    loss_weight: 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and with the ts_loss_weigh tset to 0.1 and the normal loss weight set to 0.9\n",
    "Accuracy plateaus at .79, which is very close to the accuracy of the teacher model, and peaks at 0.8 before falling downwards as the model overfits the teacher model (teacher model loss starts dropping, normal label loss holds constant, accuracy goes down) with an accuracy of .799 on iteration 100000 dropping to .798 by iteration 126000\n",
    "\n",
    "Teacher-student training appears to have no benefit over normal training for the built-in CIFAR10 dataset using reLUs, which converges faster on its own than with the teacher-student labels.\n",
    "\n",
    "Teacher-student training with a student model using sigmoid activations instead of reLUs is completely stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABFCAYAAABE+y1cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff568ee7b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im = plt.imread('ts_cifar10_graph.png')\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
