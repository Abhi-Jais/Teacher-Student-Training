{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "from caffe import layers as L\n",
    "from caffe import params as P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by defining the structure of the LeNet using Python code, rather than editing the protobuf directly. From here we can translate a teacher-student model.\n",
    "\n",
    "https://github.com/nigroup/nideep/blob/master/examples/parallel_train/verify_parallel_training.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_source = \"/opt/caffe/examples/mnist/mnist_train_lmdb\"\n",
    "test_source = \"/opt/caffe/examples/mnist/mnist_test_lmdb\"\n",
    "\n",
    "train_bs = 64\n",
    "test_bs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def le_net(train_lmdb, test_lmdb, batch_size = 64):\n",
    "    net = caffe.NetSpec() # creates empty network\n",
    "    net.data, net.label = L.Data(batch_size=train_bs, \n",
    "                                 backend=P.Data.LMDB, \n",
    "                                 source=train_lmdb,\n",
    "                                 transform_param={\"scale\":1.0/255.0}, \n",
    "                                 ntop=2,\n",
    "                                 include={\"phase\":caffe.TRAIN}\n",
    "                                )\n",
    "    net.test_data, net.test_label = L.Data(top=[\"data\", \"label\"],\n",
    "                                           batch_size=test_bs,\n",
    "                                           backend=P.Data.LMDB, \n",
    "                                           source=test_lmdb,\n",
    "                                           transform_param={\"scale\":1.0/255.0}, \n",
    "                                           ntop=2,\n",
    "                                           include={\"phase\":caffe.TEST}\n",
    "                                          )\n",
    "    net.conv1 = L.Convolution(bottom = \"data\", # does a 5x5 convolution with stride 1 on net.data\n",
    "                              kernel_h=5, # or use kernel_size\n",
    "                              kernel_w=5, \n",
    "                              stride_h=1,\n",
    "                              stride_w=1,\n",
    "                              num_output=20, \n",
    "                              weight_filler={\"type\":\"xavier\"}, # use Xavier weight initializations\n",
    "                              bias_filler={\"type\":\"constant\"}, # biases start off at 0\n",
    "                              param=[{\"lr_mult\":1}, # weights have standard learning rate\n",
    "                                     {\"lr_mult\":2}] # bias has double learning rate\n",
    "                             ) \n",
    "    net.pool1 = L.Pooling(net.conv1, # 2x2 maxPooling with stride 2 on net.conv1\n",
    "                          kernel_size=2, \n",
    "                          stride_h=2, # or use stride\n",
    "                          stride_w=2, \n",
    "                          pool=P.Pooling.MAX\n",
    "                         )\n",
    "    net.conv2 = L.Convolution(net.pool1,\n",
    "                              kernel_h=5,\n",
    "                              kernel_w=5,\n",
    "                              stride_h=1,\n",
    "                              stride_w=1,\n",
    "                              num_output=50,\n",
    "                              weight_filler={\"type\":\"xavier\"},\n",
    "                              bias_filler={\"type\":\"constant\"},\n",
    "                              param=[{\"lr_mult\":1},\n",
    "                                     {\"lr_mult\":2}]\n",
    "                             )\n",
    "    net.pool2 = L.Pooling(net.conv2,\n",
    "                          kernel_h=2,\n",
    "                          kernel_w=2,\n",
    "                          stride=2,\n",
    "                          pool=P.Pooling.MAX\n",
    "                         )\n",
    "    net.ip1 = L.InnerProduct(net.pool2, \n",
    "                             num_output=500,\n",
    "                             weight_filler={\"type\":\"xavier\"},\n",
    "                             bias_filler={\"type\":\"constant\"},\n",
    "                             param=[{\"lr_mult\":1},\n",
    "                                    {\"lr_mult\":2}]\n",
    "                            )\n",
    "    net.relu1 = L.ReLU(net.ip1,\n",
    "                       in_place=True\n",
    "                      )\n",
    "    net.ip2 = L.InnerProduct(net.relu1,\n",
    "                             num_output=100,\n",
    "                             weight_filler={\"type\":\"xavier\"},\n",
    "                             bias_filler={\"type\":\"constant\"},\n",
    "                             param=[{\"lr_mult\":1},\n",
    "                                    {\"lr_mult\":2}]\n",
    "                            )\n",
    "    net.accuracy = L.Accuracy(net.ip2, net.label,\n",
    "                              include={\"phase\": caffe.TEST}\n",
    "                             )\n",
    "    net.loss = L.SoftmaxWithLoss(net.ip2, net.label)\n",
    "    return net.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_le_net(train_lmdb, test_lmdb, batch_size = 64):\n",
    "    net = caffe.NetSpec() # creates empty network\n",
    "    # data layers\n",
    "    net.data, net.label = L.Data(batch_size=train_bs, backend=P.Data.LMDB, source=train_lmdb,\n",
    "                                 transform_param={\"scale\":1.0/255.0}, ntop=2, include={\"phase\":caffe.TRAIN})\n",
    "    net.test_data, net.test_label = L.Data(top=[\"data\", \"label\"], batch_size=test_bs, backend=P.Data.LMDB, \n",
    "                                           source=test_lmdb, transform_param={\"scale\":1.0/255.0}, ntop=2,\n",
    "                                           include={\"phase\":caffe.TEST})\n",
    "    net.conv_t1 = L.Convolution(bottom = \"data\", kernel_size=5, stride_h=1, stride_w=1, num_output=20, \n",
    "                              weight_filler={\"type\":\"xavier\"}, bias_filler={\"type\":\"constant\"},\n",
    "                              param=[{\"lr_mult\":1},{\"lr_mult\":2}]) \n",
    "    net.pool_t1 = L.Pooling(net.conv_t1, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    net.conv_t2 = L.Convolution(net.pool_t1, kernel_size=5, stride=1, num_output=50, weight_filler={\"type\":\"xavier\"},\n",
    "                              bias_filler={\"type\":\"constant\"}, param=[{\"lr_mult\":1}, {\"lr_mult\":2}])\n",
    "    net.pool_t2 = L.Pooling(net.conv_t2, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    net.ip_t1 = L.InnerProduct(net.pool_t2, num_output=500, weight_filler={\"type\":\"xavier\"},\n",
    "                             bias_filler={\"type\":\"constant\"}, param=[{\"lr_mult\":1},{\"lr_mult\":2}])\n",
    "    net.relu_t1 = L.ReLU(net.ip_t1, in_place=True)\n",
    "    net.ip_t2 = L.InnerProduct(net.relu_t1, num_output=100, weight_filler={\"type\":\"xavier\"},\n",
    "                             bias_filler={\"type\":\"constant\"}, param=[{\"lr_mult\":1},{\"lr_mult\":2}])\n",
    "    net.accuracy = L.Accuracy(net.ip_t2, net.label, include={\"phase\": caffe.TEST})\n",
    "    net.loss = L.SoftmaxWithLoss(net.ip_t2, net.label, loss_weight=1)\n",
    "    return net.to_proto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python-to-protobuf file converts perfectly, with the exception of the test data layer, which creates 4 tops: test_data, test_label, data, and label. Just delete the test_data and test_label tops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"teacher_lenet.prototxt\", \"w\") as fin:\n",
    "    fin.write(str(teacher_le_net(train_source, test_source)))\n",
    "    \n",
    "    layer {\n",
    "        name: \"sf_t1\"\n",
    "        type: \"Softmax\"\n",
    "        bottom: \"ip_t2\"\n",
    "        top: \"sf_t1\"\n",
    "    }\n",
    "    \n",
    "    layer {\n",
    "        name: \"ts_loss\"\n",
    "        type: \"SigmoidCrossEntropyLoss\"\n",
    "        bottom: \"ip_s2\"\n",
    "        bottom: \"sf_t1\"\n",
    "        top: \"ts_loss\"\n",
    "        loss_weight: 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_le_net(train_lmdb, test_lmdb, batch_size = 64):\n",
    "    net = caffe.NetSpec() # creates empty network\n",
    "    # data layers\n",
    "    net.data, net.label = L.Data(batch_size=train_bs, backend=P.Data.LMDB, source=train_lmdb,\n",
    "                                 transform_param={\"scale\":1.0/255.0}, ntop=2, include={\"phase\":caffe.TRAIN})\n",
    "    net.test_data, net.test_label = L.Data(top=[\"data\", \"label\"], batch_size=test_bs, backend=P.Data.LMDB, \n",
    "                                           source=test_lmdb, transform_param={\"scale\":1.0/255.0}, ntop=2,\n",
    "                                           include={\"phase\":caffe.TEST})\n",
    "    # student net\n",
    "    net.conv_s1 = L.Convolution(bottom = \"data\", kernel_size=5, stride_h=1, stride_w=1, num_output=20, \n",
    "                              weight_filler={\"type\":\"xavier\"}, bias_filler={\"type\":\"constant\"},\n",
    "                              param=[{\"lr_mult\":1},{\"lr_mult\":2}]) \n",
    "    net.pool_s1 = L.Pooling(net.conv_s1, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    net.conv_s2 = L.Convolution(net.pool_s1, kernel_size=5, stride=1, num_output=50, weight_filler={\"type\":\"xavier\"},\n",
    "                              bias_filler={\"type\":\"constant\"}, param=[{\"lr_mult\":1}, {\"lr_mult\":2}])\n",
    "    net.pool_s2 = L.Pooling(net.conv_s2, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    net.ip_s1 = L.InnerProduct(net.pool_s2, num_output=500, weight_filler={\"type\":\"xavier\"},\n",
    "                             bias_filler={\"type\":\"constant\"}, param=[{\"lr_mult\":1},{\"lr_mult\":2}])\n",
    "    net.relu_s1 = L.ReLU(net.ip_s1, in_place=True)\n",
    "    net.ip_s2 = L.InnerProduct(net.relu_s1, num_output=100, weight_filler={\"type\":\"xavier\"},\n",
    "                             bias_filler={\"type\":\"constant\"}, param=[{\"lr_mult\":1},{\"lr_mult\":2}])\n",
    "    # teacher net\n",
    "    net.conv_t1 = L.Convolution(bottom = \"data\", kernel_size=5, stride=1, num_output=20, \n",
    "                              param=[{\"lr_mult\":0},{\"lr_mult\":0}]) \n",
    "    net.pool_t1 = L.Pooling(net.conv_t1, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    net.conv_t2 = L.Convolution(net.pool_t1, kernel_size=5, stride=1, num_output=50, param=[{\"lr_mult\":0}, {\"lr_mult\":0}])\n",
    "    net.pool_t2 = L.Pooling(net.conv_t2, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    net.ip_t1 = L.InnerProduct(net.pool_t2, num_output=500, param=[{\"lr_mult\":0},{\"lr_mult\":0}])\n",
    "    net.relu_t1 = L.ReLU(net.ip_t1, in_place=True)\n",
    "    net.ip_t2 = L.InnerProduct(net.relu_t1, num_output=100, param=[{\"lr_mult\":0},{\"lr_mult\":0}])\n",
    "    # accuracy and loss\n",
    "    net.accuracy = L.Accuracy(net.ip_s2, net.label, include={\"phase\": caffe.TEST})\n",
    "    net.loss = L.SoftmaxWithLoss(net.ip_s2, net.label, loss_weight=0.5)\n",
    "    net.ts_loss = L.SoftmaxWithLoss(net.ip_s2, net.ip_t2, loss_weight=0.5)\n",
    "    return net.to_proto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare the teacher-student net by first loading in the trained student net. We then create the framework for the teacher-student network and then fill in the weights of the teacher section with the teacher model's weights. Note that the teacher model's layers have the same names as the teacher layers within the teacher-student model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_net = caffe.Net(\"student_lenet.prototxt\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer {\n",
       "  name: \"data\"\n",
       "  type: \"Data\"\n",
       "  top: \"data\"\n",
       "  top: \"label\"\n",
       "  include {\n",
       "    phase: TRAIN\n",
       "  }\n",
       "  transform_param {\n",
       "    scale: 0.00392156885937\n",
       "  }\n",
       "  data_param {\n",
       "    source: \"/opt/caffe/examples/mnist/mnist_train_lmdb\"\n",
       "    batch_size: 64\n",
       "    backend: LMDB\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"test_data\"\n",
       "  type: \"Data\"\n",
       "  top: \"test_data\"\n",
       "  top: \"test_label\"\n",
       "  top: \"data\"\n",
       "  top: \"label\"\n",
       "  include {\n",
       "    phase: TEST\n",
       "  }\n",
       "  transform_param {\n",
       "    scale: 0.00392156885937\n",
       "  }\n",
       "  data_param {\n",
       "    source: \"/opt/caffe/examples/mnist/mnist_test_lmdb\"\n",
       "    batch_size: 100\n",
       "    backend: LMDB\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"conv_s1\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"data\"\n",
       "  top: \"conv_s1\"\n",
       "  param {\n",
       "    lr_mult: 1.0\n",
       "  }\n",
       "  param {\n",
       "    lr_mult: 2.0\n",
       "  }\n",
       "  convolution_param {\n",
       "    num_output: 20\n",
       "    kernel_size: 5\n",
       "    weight_filler {\n",
       "      type: \"xavier\"\n",
       "    }\n",
       "    bias_filler {\n",
       "      type: \"constant\"\n",
       "    }\n",
       "    stride_h: 1\n",
       "    stride_w: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"pool_s1\"\n",
       "  type: \"Pooling\"\n",
       "  bottom: \"conv_s1\"\n",
       "  top: \"pool_s1\"\n",
       "  pooling_param {\n",
       "    pool: MAX\n",
       "    kernel_size: 2\n",
       "    stride: 2\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"conv_s2\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"pool_s1\"\n",
       "  top: \"conv_s2\"\n",
       "  param {\n",
       "    lr_mult: 1.0\n",
       "  }\n",
       "  param {\n",
       "    lr_mult: 2.0\n",
       "  }\n",
       "  convolution_param {\n",
       "    num_output: 50\n",
       "    kernel_size: 5\n",
       "    stride: 1\n",
       "    weight_filler {\n",
       "      type: \"xavier\"\n",
       "    }\n",
       "    bias_filler {\n",
       "      type: \"constant\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"pool_s2\"\n",
       "  type: \"Pooling\"\n",
       "  bottom: \"conv_s2\"\n",
       "  top: \"pool_s2\"\n",
       "  pooling_param {\n",
       "    pool: MAX\n",
       "    kernel_size: 2\n",
       "    stride: 2\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"ip_s1\"\n",
       "  type: \"InnerProduct\"\n",
       "  bottom: \"pool_s2\"\n",
       "  top: \"ip_s1\"\n",
       "  param {\n",
       "    lr_mult: 1.0\n",
       "  }\n",
       "  param {\n",
       "    lr_mult: 2.0\n",
       "  }\n",
       "  inner_product_param {\n",
       "    num_output: 500\n",
       "    weight_filler {\n",
       "      type: \"xavier\"\n",
       "    }\n",
       "    bias_filler {\n",
       "      type: \"constant\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"relu_s1\"\n",
       "  type: \"ReLU\"\n",
       "  bottom: \"ip_s1\"\n",
       "  top: \"ip_s1\"\n",
       "}\n",
       "layer {\n",
       "  name: \"ip_s2\"\n",
       "  type: \"InnerProduct\"\n",
       "  bottom: \"ip_s1\"\n",
       "  top: \"ip_s2\"\n",
       "  param {\n",
       "    lr_mult: 1.0\n",
       "  }\n",
       "  param {\n",
       "    lr_mult: 2.0\n",
       "  }\n",
       "  inner_product_param {\n",
       "    num_output: 100\n",
       "    weight_filler {\n",
       "      type: \"xavier\"\n",
       "    }\n",
       "    bias_filler {\n",
       "      type: \"constant\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"conv_t1\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"data\"\n",
       "  top: \"conv_t1\"\n",
       "  param {\n",
       "    lr_mult: 0.0\n",
       "  }\n",
       "  param {\n",
       "    lr_mult: 0.0\n",
       "  }\n",
       "  convolution_param {\n",
       "    num_output: 20\n",
       "    kernel_size: 5\n",
       "    stride: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"pool_t1\"\n",
       "  type: \"Pooling\"\n",
       "  bottom: \"conv_s1\"\n",
       "  top: \"pool_t1\"\n",
       "  pooling_param {\n",
       "    pool: MAX\n",
       "    kernel_size: 2\n",
       "    stride: 2\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"conv_t2\"\n",
       "  type: \"Convolution\"\n",
       "  bottom: \"pool_s1\"\n",
       "  top: \"conv_t2\"\n",
       "  param {\n",
       "    lr_mult: 0.0\n",
       "  }\n",
       "  param {\n",
       "    lr_mult: 0.0\n",
       "  }\n",
       "  convolution_param {\n",
       "    num_output: 50\n",
       "    kernel_size: 5\n",
       "    stride: 1\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"pool_t2\"\n",
       "  type: \"Pooling\"\n",
       "  bottom: \"conv_s2\"\n",
       "  top: \"pool_t2\"\n",
       "  pooling_param {\n",
       "    pool: MAX\n",
       "    kernel_size: 2\n",
       "    stride: 2\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"ip_t1\"\n",
       "  type: \"InnerProduct\"\n",
       "  bottom: \"pool_s2\"\n",
       "  top: \"ip_t1\"\n",
       "  param {\n",
       "    lr_mult: 0.0\n",
       "  }\n",
       "  param {\n",
       "    lr_mult: 0.0\n",
       "  }\n",
       "  inner_product_param {\n",
       "    num_output: 500\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"relu_t1\"\n",
       "  type: \"ReLU\"\n",
       "  bottom: \"ip_s1\"\n",
       "  top: \"ip_s1\"\n",
       "}\n",
       "layer {\n",
       "  name: \"ip_t2\"\n",
       "  type: \"InnerProduct\"\n",
       "  bottom: \"ip_s1\"\n",
       "  top: \"ip_t2\"\n",
       "  param {\n",
       "    lr_mult: 0.0\n",
       "  }\n",
       "  param {\n",
       "    lr_mult: 0.0\n",
       "  }\n",
       "  inner_product_param {\n",
       "    num_output: 100\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"accuracy\"\n",
       "  type: \"Accuracy\"\n",
       "  bottom: \"ip_s2\"\n",
       "  bottom: \"label\"\n",
       "  top: \"accuracy\"\n",
       "  include {\n",
       "    phase: TEST\n",
       "  }\n",
       "}\n",
       "layer {\n",
       "  name: \"loss\"\n",
       "  type: \"SoftmaxWithLoss\"\n",
       "  bottom: \"ip_s2\"\n",
       "  bottom: \"label\"\n",
       "  top: \"loss\"\n",
       "  loss_weight: 0.5\n",
       "}\n",
       "layer {\n",
       "  name: \"ts_loss\"\n",
       "  type: \"SigmoidCrossEntropyLossLayer\"\n",
       "  bottom: \"ip_s2\"\n",
       "  bottom: \"ip_t2\"\n",
       "  top: \"ts_loss\"\n",
       "  loss_weight: 0.5\n",
       "}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_le_net(train_source, test_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"ts_lenet.prototxt\", \"w\") as fin:\n",
    "    fin.write(str(ts_le_net(train_source, test_source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_net = caffe.Net(\"ts_lenet.prototxt\", \"snapshots/trained.caffemodel\", caffe.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_net2 = caffe.Net(\"ts_lenet.prototxt\", \"snapshots/trained.caffemodel\", caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': array(0.9900000095367432, dtype=float32),\n",
       " 'loss': array(0.011848684400320053, dtype=float32),\n",
       " 'ts_loss': array(106.17877960205078, dtype=float32)}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_net2.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param=list({\"lr_mult\":1}, # weights have standard learning rate\n",
    "                                          \"lr_mult\":2}) # bias has double learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr_mult': 2}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"lr_mult\":1,\n",
    " \"lr_mult\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param=[{'lr_mult':1, 'decay_mult':1},\n",
    "        {'lr_mult':2, 'decay_mult':0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'decay_mult': 1, 'lr_mult': 1}, {'decay_mult': 0, 'lr_mult': 2}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param=[{\"lr_mult\":1},\n",
    "                                    {\"lr_mult\":2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lr_mult': 1}, {'lr_mult': 2}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ns = caffe.NetSpec()\n",
    "ns.data = L.Data(name=\"data\", \n",
    "                 include={'phase':caffe.TEST})\n",
    "ns.test_data = L.Data(name=\"data\", ntop = 0, top='data',\n",
    "                 include={'phase':caffe.TEST})\n",
    "print '{}'.format(ns.to_proto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  include {\n",
      "    phase: TRAIN\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"test_data\"\n",
      "  top: \"data\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = caffe.NetSpec()\n",
    "net.data = L.Data(name='data', \n",
    "                include={\"phase\":caffe.TRAIN},\n",
    "                ntop=1)\n",
    "net.test_data = L.Data(name='data', \n",
    "                    include={\"phase\":caffe.TEST},\n",
    "                    top='data',\n",
    "                    ntop=1)\n",
    "print '{}'.format(net.to_proto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  include {\n",
      "    phase: TRAIN\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = caffe.NetSpec()\n",
    "net.data = L.Data(name='data', \n",
    "                include={\"phase\":caffe.TRAIN},\n",
    "                ntop=1)\n",
    "net.test_data = L.Data(name='data', \n",
    "                    include={\"phase\":caffe.TEST},\n",
    "                    top='data',\n",
    "                    ntop=0)\n",
    "print '{}'.format(net.to_proto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# teacher_lenet.prototxt\n",
    "\n",
    "layer {\n",
    "  name: \"data\"\n",
    "  type: \"Data\"\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TRAIN\n",
    "  }\n",
    "  transform_param {\n",
    "    scale: 0.00392156885937\n",
    "  }\n",
    "  data_param {\n",
    "    source: \"/opt/caffe/examples/mnist/mnist_train_lmdb\"\n",
    "    batch_size: 64\n",
    "    backend: LMDB\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"test_data\"\n",
    "  type: \"Data\"\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "  transform_param {\n",
    "    scale: 0.00392156885937\n",
    "  }\n",
    "  data_param {\n",
    "    source: \"/opt/caffe/examples/mnist/mnist_test_lmdb\"\n",
    "    batch_size: 100\n",
    "    backend: LMDB\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv_t1\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"data\"\n",
    "  top: \"conv_t1\"\n",
    "  param {\n",
    "    lr_mult: 1.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2.0\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 20\n",
    "    kernel_size: 5\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "    stride_h: 1\n",
    "    stride_w: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool_t1\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv_t1\"\n",
    "  top: \"pool_t1\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv_t2\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"pool_t1\"\n",
    "  top: \"conv_t2\"\n",
    "  param {\n",
    "    lr_mult: 1.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2.0\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 50\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool_t2\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv_t2\"\n",
    "  top: \"pool_t2\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ip_t1\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"pool_t2\"\n",
    "  top: \"ip_t1\"\n",
    "  param {\n",
    "    lr_mult: 1.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2.0\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 500\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"relu_t1\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"ip_t1\"\n",
    "  top: \"ip_t1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"ip_t2\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"ip_t1\"\n",
    "  top: \"ip_t2\"\n",
    "  param {\n",
    "    lr_mult: 1.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2.0\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 100\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"accuracy\"\n",
    "  type: \"Accuracy\"\n",
    "  bottom: \"ip_t2\"\n",
    "  bottom: \"label\"\n",
    "  top: \"accuracy\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"loss\"\n",
    "  type: \"SoftmaxWithLoss\"\n",
    "  bottom: \"ip_t2\"\n",
    "  bottom: \"label\"\n",
    "  top: \"loss\"\n",
    "  loss_weight: 1.0\n",
    "}\n",
    "\n",
    "# ts_lenet.prototxt\n",
    "\n",
    "layer {\n",
    "  name: \"data\"\n",
    "  type: \"Data\"\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TRAIN\n",
    "  }\n",
    "  transform_param {\n",
    "    scale: 0.00392156885937\n",
    "  }\n",
    "  data_param {\n",
    "    source: \"/opt/caffe/examples/mnist/mnist_train_lmdb\"\n",
    "    batch_size: 64\n",
    "    backend: LMDB\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"test_data\"\n",
    "  type: \"Data\"\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "  transform_param {\n",
    "    scale: 0.00392156885937\n",
    "  }\n",
    "  data_param {\n",
    "    source: \"/opt/caffe/examples/mnist/mnist_test_lmdb\"\n",
    "    batch_size: 100\n",
    "    backend: LMDB\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv_s1\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"data\"\n",
    "  top: \"conv_s1\"\n",
    "  param {\n",
    "    lr_mult: 1.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2.0\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 20\n",
    "    kernel_size: 5\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "    stride_h: 1\n",
    "    stride_w: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool_s1\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv_s1\"\n",
    "  top: \"pool_s1\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv_s2\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"pool_s1\"\n",
    "  top: \"conv_s2\"\n",
    "  param {\n",
    "    lr_mult: 1.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2.0\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 50\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool_s2\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv_s2\"\n",
    "  top: \"pool_s2\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ip_s1\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"pool_s2\"\n",
    "  top: \"ip_s1\"\n",
    "  param {\n",
    "    lr_mult: 1.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2.0\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 500\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"relu_s1\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"ip_s1\"\n",
    "  top: \"ip_s1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"ip_s2\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"ip_s1\"\n",
    "  top: \"ip_s2\"\n",
    "  param {\n",
    "    lr_mult: 1.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2.0\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 100\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv_t1\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"data\"\n",
    "  top: \"conv_t1\"\n",
    "  param {\n",
    "    lr_mult: 0.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 0.0\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 20\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool_t1\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv_t1\"\n",
    "  top: \"pool_t1\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv_t2\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"pool_t1\"\n",
    "  top: \"conv_t2\"\n",
    "  param {\n",
    "    lr_mult: 0.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 0.0\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 50\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool_t2\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv_t2\"\n",
    "  top: \"pool_t2\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ip_t1\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"pool_t2\"\n",
    "  top: \"ip_t1\"\n",
    "  param {\n",
    "    lr_mult: 0.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 0.0\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 500\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"relu_t1\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"ip_t1\"\n",
    "  top: \"ip_t1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"ip_t2\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"ip_t1\"\n",
    "  top: \"ip_t2\"\n",
    "  param {\n",
    "    lr_mult: 0.0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 0.0\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 100\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"sf_s1\"\n",
    "  type: \"Softmax\"\n",
    "  bottom: \"ip_s2\"\n",
    "  top: \"sf_s1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"sf_t1\"\n",
    "  type: \"Softmax\"\n",
    "  bottom: \"ip_t2\"\n",
    "  top: \"sf_t1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"accuracy\"\n",
    "  type: \"Accuracy\"\n",
    "  bottom: \"ip_s2\"\n",
    "  bottom: \"label\"\n",
    "  top: \"accuracy\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"loss\"\n",
    "  type: \"SoftmaxWithLoss\"\n",
    "  bottom: \"ip_s2\"\n",
    "  bottom: \"label\"\n",
    "  top: \"loss\"\n",
    "  loss_weight: 0.01\n",
    "}\n",
    "layer {\n",
    "  name: \"ts_loss\"\n",
    "  type: \"SigmoidCrossEntropyLoss\"\n",
    "  bottom: \"sf_s1\"\n",
    "  bottom: \"sf_t1\"\n",
    "  top: \"ts_loss\"\n",
    "  loss_weight: .99\n",
    "}\n",
    "\n",
    "\n",
    "# command to run on terminal\n",
    "caffe train -gpu all -solver ts_lenet_solver.prototxt -weights snapshots/teacher.caffemodel \n",
    "\n",
    "# command to save output on terminal\n",
    "caffe train -gpu all -solver teacher_lenet_solver.prototxt 2>&1 | tee norm.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
